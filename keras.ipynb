{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgeliu1998/keras_model_tuning/blob/master/keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QQl1lUm7zmN9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import pickle\n",
        "from time import time\n",
        "import importlib # for dynamic class instantiation from a string\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pYJCnFnjwiLF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = np.random.RandomState(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUyYfdfxreXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "23c86341-18ad-409a-be54-edd10e1ee879"
      },
      "cell_type": "code",
      "source": [
        "# Mount gdrive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wwRIfdxNJ6oM",
        "colab_type": "code",
        "outputId": "5731e902-87f5-40c7-f6cd-169d13157d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/pima-indians-diabetes.csv\", header=None)\n",
        "df.head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1   2   3    4     5      6   7  8\n",
              "0  6  148  72  35    0  33.6  0.627  50  1\n",
              "1  1   85  66  29    0  26.6  0.351  31  0\n",
              "2  8  183  64   0    0  23.3  0.672  32  1\n",
              "3  1   89  66  23   94  28.1  0.167  21  0\n",
              "4  0  137  40  35  168  43.1  2.288  33  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "eJ-kaPbGKG7B",
        "colab_type": "code",
        "outputId": "f10124fd-e17d-4d04-e137-b4031281895b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the features and labels as np arrays\n",
        "X, y = df.values[:, 0:8], df.values[:, 8]\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 8) (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Che2aHnO5Q6v",
        "colab_type": "code",
        "outputId": "1df38b5c-f59d-4248-ca54-a2d74af0de93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Get baseline accuracy using XGBoost\n",
        "clf = xgb.XGBClassifier()\n",
        "cv = StratifiedKFold(n_splits=3, random_state=seed)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv=cv)\n",
        "\n",
        "print(\"Mean Accuracy: {:.2%}, Standard Deviation: {:.2%}\".format(scores.mean(), scores.std()))\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 77.61%, Standard Deviation: 3.07%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HCQ1-GuByxYx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SequentialModel:\n",
        "  \"\"\"\n",
        "  The base class for a Neural Networks model\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, input_dim, num_layers, num_units, \n",
        "               activation, activation_out, \n",
        "               loss, initializer, optimizer, learning_rate, \n",
        "               metrics, epochs, batch_size, one_hot=False):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "      input_dim: int, number of features\n",
        "      num_layers: int, number of layers of the model (excluding the input layer)\n",
        "      num_units: list, number of units in each layer(excluding the input layer)\n",
        "      activation: str, activation function used in all layers except output\n",
        "      activation_out: str, activation function used in output layer\n",
        "      loss: str, loss functon\n",
        "      initializer: str, kernel initializer\n",
        "      optimizer: str, optimizer\n",
        "      metrics: list of strings, metrics used\n",
        "      epochs: int, number of epochs to train for\n",
        "      batch_size: int, number of samples per batch\n",
        "      one_hot: bool, whether one hot encoding is needed\n",
        "    \"\"\"\n",
        "    self.input_dim = input_dim\n",
        "    self.num_layers = num_layers\n",
        "    self.num_units = num_units\n",
        "    self.activation = activation\n",
        "    self.activation_out = activation_out\n",
        "    self.loss = loss\n",
        "    self.initializer = initializer\n",
        "    self.optimizer = optimizer\n",
        "    self.learning_rate = learning_rate\n",
        "    self.metrics = metrics\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.one_hot = one_hot\n",
        "    \n",
        "    # Initialize the sequential model\n",
        "    self.model = Sequential()\n",
        "  \n",
        "    \n",
        "  def build_model(self):\n",
        "    \"\"\"\n",
        "    Adds layers and compiles the model\n",
        "    \"\"\"\n",
        "    # Ensure num_units tuple's length is the same as num_layers\n",
        "    if self.num_layers != len(self.num_units):\n",
        "      # Expand the list by repeating number of nodes except for last layer\n",
        "      num_nodes, num_nodes_out = self.num_units[0], self.num_units[-1]\n",
        "      self.num_units = [i for i in range(self.num_layers-1) for i in [num_nodes]]\n",
        "      self.num_units.append(num_nodes_out) \n",
        " \n",
        "    # Loop thru all the layers\n",
        "    for i in range(self.num_layers):\n",
        "      # different layers should have different setups\n",
        "      if i == 0: # input and first hidden layer\n",
        "        self.model.add(Dense(units=self.num_units[i],\n",
        "                             input_dim=self.input_dim,\n",
        "                             kernel_initializer=self.initializer,\n",
        "                             activation=self.activation)) \n",
        "      elif i+1 == self.num_layers: # output layer\n",
        "        self.model.add(Dense(units=self.num_units[i],\n",
        "                             kernel_initializer=self.initializer,\n",
        "                             activation=self.activation_out))\n",
        "      else: # hidden layers\n",
        "        self.model.add(Dense(units=self.num_units[i],\n",
        "                            kernel_initializer=self.initializer,\n",
        "                            activation=self.activation))\n",
        "    \n",
        "    # Instantiate the optimizer class\n",
        "    optimizer_class = getattr(importlib.import_module(\"keras.optimizers\"), \n",
        "                             self.optimizer)\n",
        "    self.optimizer = optimizer_class(lr=self.learning_rate)\n",
        "    # Compile the model\n",
        "    self.model.compile(loss=self.loss,\n",
        "                       optimizer=self.optimizer,\n",
        "                       metrics=self.metrics)\n",
        "        \n",
        "  \n",
        "  def evaluate_model(self, X, y, n_splits=3):\n",
        "    \"\"\"\n",
        "    Evaluates the model using cross-validation.\n",
        "    \n",
        "    Params:\n",
        "      X: np.array, features\n",
        "      y: np.array, labels\n",
        "      n_splits: int, number of folds for the cross-validation\n",
        "    Returns:\n",
        "      mean_accuracy: float, the average accuracy based on the cross-validation.\n",
        "    \n",
        "    \"\"\"\n",
        "    score_lst = []\n",
        "    t1 = time()\n",
        "    \n",
        "    print(\"Starting {}-fold cross-validation...\".format(n_splits))\n",
        "    \n",
        "    kfold = StratifiedKFold(n_splits=n_splits, \n",
        "                            shuffle=True, \n",
        "                            random_state=seed)\n",
        "    \n",
        "    # Loop through the different folds\n",
        "    for train_index, test_index in kfold.split(X, y):\n",
        "      # Do one-hot encoding when needed\n",
        "      if self.one_hot:\n",
        "        y_one_hot = to_categorical(y)\n",
        "      else:\n",
        "        y_one_hot = y\n",
        "        \n",
        "      self.model.fit(X[train_index],\n",
        "                     y_one_hot[train_index],\n",
        "                     epochs=self.epochs,\n",
        "                     batch_size=self.batch_size,\n",
        "                     verbose=0)\n",
        "        \n",
        "      scores = self.model.evaluate(X[test_index],\n",
        "                                   y_one_hot[test_index], \n",
        "                                   verbose=0)\n",
        "            \n",
        "      # The second item is accuracy\n",
        "      score_lst.append(scores[1])\n",
        "\n",
        "    t2 = time()\n",
        "    t = t2 - t1\n",
        "    # Convert time to mintues\n",
        "    t /= 60\n",
        "\n",
        "    print(\"Finished cross-valiation. Took {:.1f} mintues.\".format(t))\n",
        "\n",
        "    # Convert to np.array and calculate mean and sd\n",
        "    score_lst = np.array(score_lst)\n",
        "    mean_acc = score_lst.mean()\n",
        "    sd_acc = score_lst.std()\n",
        "\n",
        "    print(\"Mean Accuracy: {:.2%}, Standard Deviation: {:.2%}\".format(mean_acc, sd_acc))\n",
        "    return mean_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3QbFJkQVK4tQ",
        "colab_type": "code",
        "outputId": "bb51b1d8-50d0-4b03-c758-7ed0d033b6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "def get_defaults(input_dim=8,\n",
        "                 num_layers=2,\n",
        "                 num_units=[8, 1],\n",
        "                 activation='relu',\n",
        "                 activation_out='sigmoid',\n",
        "                 loss='binary_crossentropy',\n",
        "                 initializer='random_uniform',\n",
        "                 optimizer='adam',\n",
        "                 learning_rate=0.001,\n",
        "                 metrics=['accuracy'],\n",
        "                 epochs=10,\n",
        "                 batch_size=4,\n",
        "                 one_hot=False):\n",
        "  \"\"\"\n",
        "  Returns a dict of default hyperparameter values\n",
        "  \"\"\"\n",
        "  \n",
        "  defaults = {'input_dim': input_dim, \n",
        "              'num_layers': num_layers, \n",
        "              'num_units': num_units, \n",
        "              'activation': activation, \n",
        "              'activation_out': activation_out, \n",
        "              'loss': loss, \n",
        "              'initializer': initializer, \n",
        "              'optimizer': optimizer, \n",
        "              'learning_rate': learning_rate, \n",
        "              'metrics': metrics, \n",
        "              'epochs': epochs, \n",
        "              'batch_size': batch_size, \n",
        "              'one_hot': one_hot}\n",
        "  \n",
        "  return defaults\n",
        "\n",
        "\n",
        "defaults = get_defaults()\n",
        "defaults"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'activation_out': 'sigmoid',\n",
              " 'batch_size': 4,\n",
              " 'epochs': 10,\n",
              " 'initializer': 'random_uniform',\n",
              " 'input_dim': 8,\n",
              " 'learning_rate': 0.001,\n",
              " 'loss': 'binary_crossentropy',\n",
              " 'metrics': ['accuracy'],\n",
              " 'num_layers': 2,\n",
              " 'num_units': [8, 1],\n",
              " 'one_hot': False,\n",
              " 'optimizer': 'adam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "_ijY3XR7Ocyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1dcf38e8-5555-4f25-9795-998ffc55c3b1"
      },
      "cell_type": "code",
      "source": [
        "def build_test_model(param_dict):\n",
        "  \"\"\"\n",
        "  Builds a Neural Network model using the given params and returns the \n",
        "  cross-validation accuracy\n",
        "  \n",
        "  Params:\n",
        "    param_dict: dict - Python dict containing the tuning parameters and values\n",
        "  \n",
        "  Returns:\n",
        "    result: float - percentage accuracy based on cross-validation\n",
        "  \n",
        "  \"\"\"\n",
        "  model = SequentialModel(input_dim=param_dict['input_dim'], \n",
        "                          num_layers=param_dict['num_layers'], \n",
        "                          num_units=param_dict['num_units'],\n",
        "                          activation=param_dict['activation'], \n",
        "                          activation_out=param_dict['activation_out'], \n",
        "                          loss=param_dict['loss'], \n",
        "                          initializer=param_dict['initializer'], \n",
        "                          optimizer=param_dict['optimizer'], \n",
        "                          learning_rate=param_dict['learning_rate'], \n",
        "                          metrics=param_dict['metrics'], \n",
        "                          epochs=param_dict['epochs'], \n",
        "                          batch_size=param_dict['batch_size'], \n",
        "                          one_hot=param_dict['one_hot'])\n",
        "\n",
        "  model.build_model()\n",
        "  result = model.evaluate_model(X, y)\n",
        "  \n",
        "  return result\n",
        "\n",
        "# Get baseline accuracy using defauls with the defined Neural Networks class  \n",
        "build_test_model(param_dict=defaults)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 68.62%, Standard Deviation: 0.95%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6862048313005364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "2VnF5lzmLISj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define tuning parameter and corresponding options\n",
        "num_units = [4, 8, 16, 32, 64]\n",
        "num_layers = [2, 4, 8, 16, 32]\n",
        "loss = ['binary_crossentropy', 'categorical_crossentropy', 'sparse_categorical_crossentropy']\n",
        "initializer = ['random_uniform', 'random_normal', 'TruncatedNormal', 'glorot_normal', 'glorot_uniform']\n",
        "learning_rate = [0.001, 0.002, 0.01, 0.1, 1]\n",
        "optimizer = ['adam', 'adamax', 'adagrad', 'sgd', 'rmsprop']\n",
        "epochs = [10, 20, 40, 80, 160]\n",
        "batch_size = [1, 2, 4, 8, 16]\n",
        "\n",
        "\n",
        "tuning_options = {'num_units': num_units,\n",
        "                  'num_layers': num_layers, \n",
        "                  'loss': loss, \n",
        "                  'initializer': initializer, \n",
        "                  'optimizer': optimizer, \n",
        "                  'learning_rate': learning_rate,\n",
        "                  'epochs': epochs, \n",
        "                  'batch_size': batch_size}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cf3kbnDie18w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3352
        },
        "outputId": "22c534ee-3ccc-492a-c340-d98d2da28970"
      },
      "cell_type": "code",
      "source": [
        "def run_test(tuning_options, X, y):\n",
        "  \"\"\"\n",
        "  Tests different hyperparameter's accurcy using the given tuning options\n",
        "  \"\"\"\n",
        "  # Initiate a dict to store all results\n",
        "  results = {}\n",
        "\n",
        "  for parameter, options in tuning_options.items():\n",
        "    results[parameter] = {}\n",
        "    # Get the default hyperparameters\n",
        "    defaults = get_defaults()\n",
        "    \n",
        "    for option in options:\n",
        "      print(\"\\nEvaluating parameter \\\"{}\\\" using value \\\"{}\\\"...\".format(parameter, option))\n",
        "      # Update the corresponding hyperparameter\n",
        "      if parameter == 'num_units':\n",
        "        defaults[parameter] == [option, 1]\n",
        "      else:\n",
        "        defaults[parameter] = option\n",
        "      try:\n",
        "        result = build_test_model(param_dict=defaults) \n",
        "        results[parameter][option] = result\n",
        "      except Exception as e: \n",
        "        results[parameter][option] = 'NaN'\n",
        "        print('Error: {}, skipping...'.format(e))\n",
        "        pass\n",
        "\n",
        "  return results\n",
        "\n",
        "results = run_test(tuning_options, X, y)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating parameter \"num_units\" using value \"4\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 68.49%, Standard Deviation: 0.93%\n",
            "\n",
            "Evaluating parameter \"num_units\" using value \"8\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 68.09%, Standard Deviation: 2.40%\n",
            "\n",
            "Evaluating parameter \"num_units\" using value \"16\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 70.18%, Standard Deviation: 1.93%\n",
            "\n",
            "Evaluating parameter \"num_units\" using value \"32\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 67.84%, Standard Deviation: 0.87%\n",
            "\n",
            "Evaluating parameter \"num_units\" using value \"64\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 67.06%, Standard Deviation: 0.43%\n",
            "\n",
            "Evaluating parameter \"num_layers\" using value \"2\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 68.11%, Standard Deviation: 2.25%\n",
            "\n",
            "Evaluating parameter \"num_layers\" using value \"4\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 70.70%, Standard Deviation: 2.79%\n",
            "\n",
            "Evaluating parameter \"num_layers\" using value \"8\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.7 mintues.\n",
            "Mean Accuracy: 65.10%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"num_layers\" using value \"16\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 1.0 mintues.\n",
            "Mean Accuracy: 65.10%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"num_layers\" using value \"32\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 1.6 mintues.\n",
            "Mean Accuracy: 65.10%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"loss\" using value \"binary_crossentropy\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 70.45%, Standard Deviation: 2.33%\n",
            "\n",
            "Evaluating parameter \"loss\" using value \"categorical_crossentropy\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Error: You are passing a target array of shape (511, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n",
            "```\n",
            "from keras.utils import to_categorical\n",
            "y_binary = to_categorical(y_int)\n",
            "```\n",
            "\n",
            "Alternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets., skipping...\n",
            "\n",
            "Evaluating parameter \"loss\" using value \"sparse_categorical_crossentropy\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 0.00%, Standard Deviation: 0.00%\n",
            "\n",
            "Evaluating parameter \"initializer\" using value \"random_uniform\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 71.62%, Standard Deviation: 1.07%\n",
            "\n",
            "Evaluating parameter \"initializer\" using value \"random_normal\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 68.76%, Standard Deviation: 4.91%\n",
            "\n",
            "Evaluating parameter \"initializer\" using value \"TruncatedNormal\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 71.35%, Standard Deviation: 0.47%\n",
            "\n",
            "Evaluating parameter \"initializer\" using value \"glorot_normal\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 64.07%, Standard Deviation: 1.01%\n",
            "\n",
            "Evaluating parameter \"initializer\" using value \"glorot_uniform\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 66.16%, Standard Deviation: 2.92%\n",
            "\n",
            "Evaluating parameter \"optimizer\" using value \"adam\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 68.36%, Standard Deviation: 2.16%\n",
            "\n",
            "Evaluating parameter \"optimizer\" using value \"adamax\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 70.58%, Standard Deviation: 3.57%\n",
            "\n",
            "Evaluating parameter \"optimizer\" using value \"adagrad\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 65.63%, Standard Deviation: 0.85%\n",
            "\n",
            "Evaluating parameter \"optimizer\" using value \"sgd\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 66.67%, Standard Deviation: 0.74%\n",
            "\n",
            "Evaluating parameter \"optimizer\" using value \"rmsprop\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 67.31%, Standard Deviation: 1.89%\n",
            "\n",
            "Evaluating parameter \"learning_rate\" using value \"0.001\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 68.10%, Standard Deviation: 1.19%\n",
            "\n",
            "Evaluating parameter \"learning_rate\" using value \"0.002\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 70.97%, Standard Deviation: 3.03%\n",
            "\n",
            "Evaluating parameter \"learning_rate\" using value \"0.01\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 65.10%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"learning_rate\" using value \"0.1\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 65.10%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"learning_rate\" using value \"1\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 34.90%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"epochs\" using value \"10\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 69.01%, Standard Deviation: 1.80%\n",
            "\n",
            "Evaluating parameter \"epochs\" using value \"20\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.8 mintues.\n",
            "Mean Accuracy: 70.32%, Standard Deviation: 2.52%\n",
            "\n",
            "Evaluating parameter \"epochs\" using value \"40\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 1.6 mintues.\n",
            "Mean Accuracy: 73.18%, Standard Deviation: 4.82%\n",
            "\n",
            "Evaluating parameter \"epochs\" using value \"80\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 3.0 mintues.\n",
            "Mean Accuracy: 74.36%, Standard Deviation: 2.71%\n",
            "\n",
            "Evaluating parameter \"epochs\" using value \"160\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 5.9 mintues.\n",
            "Mean Accuracy: 75.13%, Standard Deviation: 1.51%\n",
            "\n",
            "Evaluating parameter \"batch_size\" using value \"1\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 1.5 mintues.\n",
            "Mean Accuracy: 69.67%, Standard Deviation: 1.89%\n",
            "\n",
            "Evaluating parameter \"batch_size\" using value \"2\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.8 mintues.\n",
            "Mean Accuracy: 69.66%, Standard Deviation: 2.03%\n",
            "\n",
            "Evaluating parameter \"batch_size\" using value \"4\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 70.06%, Standard Deviation: 2.59%\n",
            "\n",
            "Evaluating parameter \"batch_size\" using value \"8\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 68.75%, Standard Deviation: 2.37%\n",
            "\n",
            "Evaluating parameter \"batch_size\" using value \"16\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 0.2 mintues.\n",
            "Mean Accuracy: 67.33%, Standard Deviation: 2.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s159Jx6Fplqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00adb5cd-3c1b-4a84-a5e5-85fb21dff5a7"
      },
      "cell_type": "code",
      "source": [
        "# Save the dict    \n",
        "with open('/content/gdrive/My Drive/cross_validation_results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
        "    print(\"Results saved to Google Drive successfully!\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results saved to Google Drive successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kozw8MO7Iu3I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the pickled results dict\n",
        "with open('/content/gdrive/My Drive/cross_validation_results.pkl', 'rb') as f:\n",
        "    tuning_results = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTns86tjLRDq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def wrangle(tuning_results):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "        tuning_results: dict, the dict loaded from pickled hyperparameter tuning results\n",
        "    \n",
        "    Returns:\n",
        "        df_long: pandas df, the wrangled long format dataframe\n",
        "    \"\"\"\n",
        "    # Save as df\n",
        "    df = pd.DataFrame(tuning_results)\n",
        "    # Get the col names as value vars for melt func\n",
        "    value_vars = df.columns.tolist()\n",
        "    # Reset index and rename the index col \n",
        "    df = df.reset_index().rename(columns={'index': 'option'})\n",
        "    # Transform from wide to long format for easy plotting\n",
        "    df_long = pd.melt(df, id_vars='option', value_vars=value_vars)\n",
        "    df_long = df_long.rename(columns={'variable': 'parameter'})\n",
        "    # Exclude the zero and null values\n",
        "    df_long = df_long[~df_long['value'].isnull()]\n",
        "    df_long = df_long.query(\"value!=0 & value!='NaN'\")\n",
        "    \n",
        "    return df_long\n",
        "\n",
        "df_long = wrangle(tuning_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_xgwDiwjvHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def transform_df(df_long):\n",
        "  \"\"\"\n",
        "  Transforms the long form df into a plottable df\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate the range and sd of each parameter group and convert to a df\n",
        "  ranges = df_long.groupby('parameter').apply(lambda grp: grp.value.max() - grp.value.min())\n",
        "  sd = df_long.groupby('parameter').apply(lambda grp: grp.value.std())\n",
        "  spread = pd.concat([ranges, sd], axis=1).rename(columns={0: 'ranges', 1: 'sd'})\n",
        "\n",
        "  # Join back the df\n",
        "  df_spread = pd.merge(df_long, spread, how='left', left_on='parameter', right_index=True)\n",
        "\n",
        "  # Reorder columns\n",
        "  df_spread = df_spread[['parameter', 'option', 'value', 'ranges', 'sd']]\n",
        "\n",
        "  # Remove the row with zero value\n",
        "  df_spread = df_spread.query('ranges!=0')\n",
        "\n",
        "  # Sort the dataframe and use the resulting index to slice\n",
        "  # This ensures the plot will be ordered accordingly\n",
        "  idx = df_spread.sort_values(by=['ranges', 'option'], ascending=False).index\n",
        "  df_plot = df_spread.loc[idx, :]\n",
        "  df_plot\n",
        "  \n",
        "  return df_plot\n",
        "\n",
        "df_plot = transform_df(df_long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5SS5w_7DXZs",
        "colab_type": "code",
        "outputId": "7cd1d091-96d3-44bb-c08e-8baf51068ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        }
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(16, 12))\n",
        "df_plot['value'] = df_plot['value'].astype(float)\n",
        "sns.boxplot(x='parameter', y='value', data=df_plot, ax=ax)\n",
        "sns.swarmplot(x='parameter', y='value', data=df_plot, size=12, ax=ax)\n",
        "ax.set_xlabel('Parameters',size=20)\n",
        "ax.set_ylabel('Values',size=20)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:454: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  box_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'Values')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7cAAALCCAYAAAAF/CTFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f03bfa28198>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RzU36qL3OYb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6d9ca803-b56c-48c5-f2ed-9885ee1805d0"
      },
      "cell_type": "code",
      "source": [
        "# Get the best parameter options\n",
        "best_options = df_plot.groupby('parameter').apply(lambda grp: grp.nlargest(1, 'value'))[['parameter', 'option']].values.tolist()\n",
        "best_options"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['batch_size', 4],\n",
              " ['epochs', 160],\n",
              " ['initializer', 'random_uniform'],\n",
              " ['learning_rate', 0.002],\n",
              " ['num_layers', 4],\n",
              " ['num_units', 16],\n",
              " ['optimizer', 'adamax']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "r2LScFOJRKpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e1eafebc-1fc2-4321-c45a-1220af3b1240"
      },
      "cell_type": "code",
      "source": [
        "# Use the best_options to build a new baseline model\n",
        "defaults = get_defaults()\n",
        "\n",
        "for i in best_options:\n",
        "  if i[0] == 'num_units': # ensure num_units is a list\n",
        "    defaults[i[0]] = [i[1], 1]\n",
        "  else:\n",
        "    defaults[i[0]] = i[1]\n",
        "\n",
        "build_test_model(param_dict=defaults)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting 3-fold cross-validation...\n",
            "Finished cross-valiation. Took 6.9 mintues.\n",
            "Mean Accuracy: 76.31%, Standard Deviation: 2.83%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7630894992435268"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "xNeotHP_I9sL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define tuning parameter and corresponding options\n",
        "learning_rate = [0.00095, 0.001, 0.0018, 0.0019, 0.002, 0.003] #0.002\n",
        "\n",
        "tuning_options = {'learning_rate': learning_rate}\n",
        "\n",
        "result = run_test(tuning_options, X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVxipel4erKQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualize(result, param_tuned):\n",
        "  \"\"\"\n",
        "  Visualizes the hyperparameter tuning result\n",
        "  \n",
        "  Params:\n",
        "    result - dict, result dict returned by the run_test() func\n",
        "    param_tuned - string, one of these:\n",
        "      ['num_units', 'num_layers', 'loss', 'initializer', 'optimizer', 'learning_rate', 'epochs', 'batch_size']\n",
        "  returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  d = result[param_tuned]\n",
        "\n",
        "  xs, ys = np.array(list(d.keys())), np.array(list(d.values()))\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(12, 8))\n",
        "  plt.plot(xs, ys)  \n",
        "  ax.set_xlim(xs.min()*0.9, xs.max()*1.1)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lRbpxmcTlFI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visualize(result, 'learning_rate')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQYJljE-Owom",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now tune batch_size\n",
        "batch_size = [1, 2, 4, 8, 16, 32, 64, 128] #4\n",
        "tuning_options = {'batch_size': batch_size}\n",
        "result = run_test(tuning_options, X, y)\n",
        "visualize(result, 'batch_size')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xPHlALpxJdrh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. persisting file\n",
        "2. download pima from kaggle\n",
        "3. random search\n",
        "4. plot title\n",
        "5. code refactoring: given param dict, test results\n"
      ]
    },
    {
      "metadata": {
        "id": "IxKg9k1rRtqJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}