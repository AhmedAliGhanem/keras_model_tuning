{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgeliu1998/keras_model_tuning/blob/master/keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QQl1lUm7zmN9",
        "colab_type": "code",
        "outputId": "e368d09f-c91b-4249-d197-ec949f662f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import pickle\n",
        "from time import time\n",
        "import importlib # for dynamic class instantiation from a string\n",
        "\n",
        "#from sklearn import datasets\n",
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "#from sklearn.metrics import confusion_matrix, mean_squared_error\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#from keras import optimizers\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pYJCnFnjwiLF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = np.random.RandomState(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7XxguNB8asj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "\n",
        "X = iris['data']\n",
        "y = iris['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Che2aHnO5Q6v",
        "colab_type": "code",
        "outputId": "9156300b-8475-461d-bda5-de43daf44f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf = xgb.XGBClassifier()\n",
        "cv = StratifiedKFold(n_splits=5, random_state=seed)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv=cv)\n",
        "\n",
        "print(\"Mean Accuracy: {:.2%}, Standard Deviation: {:.2%}\".format(scores.mean(), scores.std()))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 95.33%, Standard Deviation: 3.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HCQ1-GuByxYx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SequentialModel:\n",
        "  \n",
        "  def __init__(self, input_dim, num_layers, num_units, \n",
        "               activation, activation_out, \n",
        "               loss, initializer, optimizer, learning_rate, \n",
        "               metrics, epochs, batch_size, one_hot=False):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "      input_dim: int, number of features\n",
        "      num_layers: int, number of layers of the model (excluding the input layer)\n",
        "      num_units: list, number of units in each layer(excluding the input layer)\n",
        "      activation: str, activation function used in all layers except output\n",
        "      activation_out: str, activation function used in output layer\n",
        "      loss: str, loss functon\n",
        "      initializer: str, kernel initializer\n",
        "      optimizer: str, optimizer\n",
        "      metrics: list of strings, metrics used\n",
        "      epochs: int, number of epochs to train for\n",
        "      batch_size: int, number of samples per batch\n",
        "      one_hot: bool, whether one hot encoding is needed\n",
        "    \"\"\"\n",
        "    self.input_dim = input_dim\n",
        "    self.num_layers = num_layers\n",
        "    self.num_units = num_units\n",
        "    self.activation = activation\n",
        "    self.activation_out = activation_out\n",
        "    self.loss = loss\n",
        "    self.initializer = initializer\n",
        "    self.optimizer = optimizer\n",
        "    self.learning_rate = learning_rate\n",
        "    self.metrics = metrics\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.one_hot = one_hot\n",
        "    \n",
        "    # Initialize the sequential model\n",
        "    self.model = Sequential()\n",
        "  \n",
        "    \n",
        "  def build_model(self):\n",
        "    \"\"\"\n",
        "    Adds layers and compiles the model\n",
        "    \"\"\"\n",
        "    # Ensure num_units tuple's length is the same as num_layers\n",
        "    if self.num_layers != len(self.num_units):\n",
        "      # Expand the list by repeating number of nodes except for last layer\n",
        "      num_nodes, num_nodes_out = self.num_units[0], self.num_units[-1]\n",
        "      self.num_units = [i for i in range(num_layers-1) for i in [num_nodes]]\n",
        "      self.num_units.append(num_nodes_out) \n",
        "    \n",
        "    # Loop thru all the layers\n",
        "    for i in range(self.num_layers):\n",
        "      # Different layers should have different setups\n",
        "      if i == 0: # first layer\n",
        "        self.model.add(Dense(units=self.num_units[i],\n",
        "                             input_dim=self.input_dim,\n",
        "                             kernel_initializer=initializer,\n",
        "                             activation=activation)) \n",
        "      elif i+1 == self.num_layers: # output layer\n",
        "        self.model.add(Dense(units=self.num_units[i],\n",
        "                             kernel_initializer=initializer,\n",
        "                             activation=activation_out))\n",
        "      else:\n",
        "        self.model.add(Dense(units=self.num_units[i],\n",
        "                            kernel_initializer=initializer,\n",
        "                            activation=activation))\n",
        "    \n",
        "    # Instantiate the optimizer class\n",
        "    optimizer_class = getattr(importlib.import_module(\"keras.optimizers\"), \n",
        "                             self.optimizer)\n",
        "    self.optimizer = optimizer_class(lr=self.learning_rate)\n",
        "    # Compile the model\n",
        "    self.model.compile(loss=self.loss,\n",
        "                       optimizer=self.optimizer,\n",
        "                       metrics=self.metrics)\n",
        "      \n",
        "  \n",
        "  \n",
        "  def evaluate_model(self, X, y, n_splits=3):\n",
        "    \"\"\"\n",
        "    Evaluates the model using cross-validation.\n",
        "    \n",
        "    Params:\n",
        "      X: np.array, features\n",
        "      y: np.array, labels\n",
        "      n_splits: int, number of folds for the cross-validation\n",
        "    Returns:\n",
        "      mean_accuracy: float, the average accuracy based on the cross-validation.\n",
        "    \n",
        "    \"\"\"\n",
        "    score_lst = []\n",
        "    t1 = time()\n",
        "    \n",
        "    print(\"Starting {}-fold cross-validation...\".format(n_splits))\n",
        "    \n",
        "    kfold = StratifiedKFold(n_splits=n_splits, \n",
        "                            shuffle=True, \n",
        "                            random_state=seed)\n",
        "    \n",
        "    # Loop through the different folds\n",
        "    for train_index, test_index in kfold.split(X, y):\n",
        "      # Do one-hot encoding when needed\n",
        "      if self.one_hot:\n",
        "        y_one_hot = to_categorical(y)\n",
        "      else:\n",
        "        y_one_hot = y\n",
        "        \n",
        "      self.model.fit(X[train_index],\n",
        "                     y_one_hot[train_index],\n",
        "                     epochs=self.epochs,\n",
        "                     batch_size=self.batch_size,\n",
        "                     verbose=1)\n",
        "        \n",
        "      scores = self.model.evaluate(X[test_index],\n",
        "                                   y_one_hot[test_index], \n",
        "                                   verbose=1)\n",
        "            \n",
        "      # The second item is accuracy\n",
        "      score_lst.append(scores[1])\n",
        "\n",
        "    t2 = time()\n",
        "    t = t2 - t1\n",
        "    # Convert time to mintues\n",
        "    t /= 60\n",
        "\n",
        "    print(\"Finished cross-valiation. Took {:.1f} mintues.\".format(t))\n",
        "\n",
        "    # Convert to np.array and calculate mean and sd\n",
        "    score_lst = np.array(score_lst)\n",
        "    mean_acc = score_lst.mean()\n",
        "    sd_acc = score_lst.std()\n",
        "\n",
        "    print(\"Mean Accuracy: {:.2%}, Standard Deviation: {:.2%}\".format(mean_acc, sd_acc))\n",
        "    return mean_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c5fROX9hw9aP",
        "colab_type": "code",
        "outputId": "4423cae7-2573-426b-c699-601ecfd7df5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10336
        }
      },
      "cell_type": "code",
      "source": [
        "input_dim = 4\n",
        "num_layers = 2\n",
        "num_units = (4, 3) \n",
        "activation = 'relu'\n",
        "activation_out = 'softmax'\n",
        "loss = 'binary_crossentropy'\n",
        "initializer = 'random_uniform'\n",
        "optimizer = 'adam'\n",
        "learning_rate = 0.001\n",
        "metrics = ['accuracy']\n",
        "epochs = 100\n",
        "batch_size = 5\n",
        "one_hot = True\n",
        "\n",
        "\n",
        "model = SequentialModel(input_dim=input_dim, \n",
        "                        num_layers=num_layers, \n",
        "                        num_units=num_units,\n",
        "                        activation=activation, \n",
        "                        activation_out=activation_out, \n",
        "                        loss=loss, \n",
        "                        initializer=initializer, \n",
        "                        optimizer=optimizer, \n",
        "                        learning_rate=learning_rate, \n",
        "                        metrics=metrics, \n",
        "                        epochs=epochs, \n",
        "                        batch_size=batch_size, \n",
        "                        one_hot=one_hot)\n",
        "\n",
        "model.build_model()\n",
        "model.evaluate_model(X, y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/100\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.6367 - acc: 0.6667\n",
            "Epoch 2/100\n",
            "99/99 [==============================] - 0s 953us/step - loss: 0.6361 - acc: 0.6667\n",
            "Epoch 3/100\n",
            "99/99 [==============================] - 0s 989us/step - loss: 0.6351 - acc: 0.6667\n",
            "Epoch 4/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.6335 - acc: 0.6667\n",
            "Epoch 5/100\n",
            "99/99 [==============================] - 0s 924us/step - loss: 0.6311 - acc: 0.6667\n",
            "Epoch 6/100\n",
            "99/99 [==============================] - 0s 942us/step - loss: 0.6272 - acc: 0.6667\n",
            "Epoch 7/100\n",
            "99/99 [==============================] - 0s 994us/step - loss: 0.6218 - acc: 0.6667\n",
            "Epoch 8/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.6151 - acc: 0.6667\n",
            "Epoch 9/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.6066 - acc: 0.6667\n",
            "Epoch 10/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.5971 - acc: 0.6667\n",
            "Epoch 11/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.5870 - acc: 0.6667\n",
            "Epoch 12/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.5749 - acc: 0.6768\n",
            "Epoch 13/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.5637 - acc: 0.7407\n",
            "Epoch 14/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.5525 - acc: 0.7778\n",
            "Epoch 15/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.5402 - acc: 0.7778\n",
            "Epoch 16/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.5293 - acc: 0.7778\n",
            "Epoch 17/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.5183 - acc: 0.7778\n",
            "Epoch 18/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.5079 - acc: 0.7778\n",
            "Epoch 19/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4984 - acc: 0.7778\n",
            "Epoch 20/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4896 - acc: 0.7778\n",
            "Epoch 21/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4813 - acc: 0.7778\n",
            "Epoch 22/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4740 - acc: 0.7778\n",
            "Epoch 23/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4662 - acc: 0.7778\n",
            "Epoch 24/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4595 - acc: 0.7778\n",
            "Epoch 25/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4531 - acc: 0.7778\n",
            "Epoch 26/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4470 - acc: 0.7778\n",
            "Epoch 27/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4415 - acc: 0.7778\n",
            "Epoch 28/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4363 - acc: 0.7778\n",
            "Epoch 29/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4315 - acc: 0.7778\n",
            "Epoch 30/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4270 - acc: 0.7778\n",
            "Epoch 31/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4230 - acc: 0.7778\n",
            "Epoch 32/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4189 - acc: 0.7778\n",
            "Epoch 33/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4153 - acc: 0.7778\n",
            "Epoch 34/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4120 - acc: 0.7778\n",
            "Epoch 35/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4086 - acc: 0.7778\n",
            "Epoch 36/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4056 - acc: 0.7778\n",
            "Epoch 37/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4027 - acc: 0.7778\n",
            "Epoch 38/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.4002 - acc: 0.7778\n",
            "Epoch 39/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3975 - acc: 0.7778\n",
            "Epoch 40/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3952 - acc: 0.7778\n",
            "Epoch 41/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3927 - acc: 0.7778\n",
            "Epoch 42/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3906 - acc: 0.7778\n",
            "Epoch 43/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3885 - acc: 0.7778\n",
            "Epoch 44/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3865 - acc: 0.7778\n",
            "Epoch 45/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3846 - acc: 0.7778\n",
            "Epoch 46/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3829 - acc: 0.7778\n",
            "Epoch 47/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3810 - acc: 0.7778\n",
            "Epoch 48/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3793 - acc: 0.7778\n",
            "Epoch 49/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3778 - acc: 0.7778\n",
            "Epoch 50/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3762 - acc: 0.7778\n",
            "Epoch 51/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3747 - acc: 0.7778\n",
            "Epoch 52/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3732 - acc: 0.7778\n",
            "Epoch 53/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3719 - acc: 0.7778\n",
            "Epoch 54/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3705 - acc: 0.7778\n",
            "Epoch 55/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3692 - acc: 0.7778\n",
            "Epoch 56/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3680 - acc: 0.7778\n",
            "Epoch 57/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3669 - acc: 0.7778\n",
            "Epoch 58/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3656 - acc: 0.7778\n",
            "Epoch 59/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3647 - acc: 0.7778\n",
            "Epoch 60/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3633 - acc: 0.7778\n",
            "Epoch 61/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3623 - acc: 0.7778\n",
            "Epoch 62/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3612 - acc: 0.7778\n",
            "Epoch 63/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3602 - acc: 0.7778\n",
            "Epoch 64/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3593 - acc: 0.7778\n",
            "Epoch 65/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3584 - acc: 0.7778\n",
            "Epoch 66/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3574 - acc: 0.7778\n",
            "Epoch 67/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3565 - acc: 0.7778\n",
            "Epoch 68/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3556 - acc: 0.7778\n",
            "Epoch 69/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3547 - acc: 0.7778\n",
            "Epoch 70/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3538 - acc: 0.7778\n",
            "Epoch 71/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3530 - acc: 0.7778\n",
            "Epoch 72/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3520 - acc: 0.7778\n",
            "Epoch 73/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3511 - acc: 0.7778\n",
            "Epoch 74/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3500 - acc: 0.7778\n",
            "Epoch 75/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3488 - acc: 0.7778\n",
            "Epoch 76/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3476 - acc: 0.7778\n",
            "Epoch 77/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3459 - acc: 0.7778\n",
            "Epoch 78/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3440 - acc: 0.7778\n",
            "Epoch 79/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3415 - acc: 0.7778\n",
            "Epoch 80/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3389 - acc: 0.7778\n",
            "Epoch 81/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3358 - acc: 0.7778\n",
            "Epoch 82/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3328 - acc: 0.7778\n",
            "Epoch 83/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3298 - acc: 0.7778\n",
            "Epoch 84/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3266 - acc: 0.7778\n",
            "Epoch 85/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3237 - acc: 0.7778\n",
            "Epoch 86/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3200 - acc: 0.7778\n",
            "Epoch 87/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3165 - acc: 0.7778\n",
            "Epoch 88/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3134 - acc: 0.7778\n",
            "Epoch 89/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3099 - acc: 0.8182\n",
            "Epoch 90/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3061 - acc: 0.8485\n",
            "Epoch 91/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.3024 - acc: 0.8519\n",
            "Epoch 92/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2999 - acc: 0.8653\n",
            "Epoch 93/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2965 - acc: 0.8754\n",
            "Epoch 94/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2932 - acc: 0.8687\n",
            "Epoch 95/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2899 - acc: 0.8788\n",
            "Epoch 96/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2862 - acc: 0.8822\n",
            "Epoch 97/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2836 - acc: 0.9596\n",
            "Epoch 98/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2800 - acc: 0.9663\n",
            "Epoch 99/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2770 - acc: 0.9562\n",
            "Epoch 100/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2744 - acc: 0.9596\n",
            "51/51 [==============================] - 0s 733us/step\n",
            "Epoch 1/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2730 - acc: 0.9529\n",
            "Epoch 2/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2709 - acc: 0.9495\n",
            "Epoch 3/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2686 - acc: 0.9562\n",
            "Epoch 4/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2646 - acc: 0.9596\n",
            "Epoch 5/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2622 - acc: 0.9596\n",
            "Epoch 6/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2589 - acc: 0.9562\n",
            "Epoch 7/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2566 - acc: 0.9529\n",
            "Epoch 8/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2540 - acc: 0.9562\n",
            "Epoch 9/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2524 - acc: 0.9529\n",
            "Epoch 10/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2485 - acc: 0.9630\n",
            "Epoch 11/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2465 - acc: 0.9630\n",
            "Epoch 12/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2439 - acc: 0.9529\n",
            "Epoch 13/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.9562\n",
            "Epoch 14/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2397 - acc: 0.9562\n",
            "Epoch 15/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2366 - acc: 0.9562\n",
            "Epoch 16/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2340 - acc: 0.9596\n",
            "Epoch 17/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2316 - acc: 0.9596\n",
            "Epoch 18/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2293 - acc: 0.9630\n",
            "Epoch 19/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2271 - acc: 0.9630\n",
            "Epoch 20/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2251 - acc: 0.9697\n",
            "Epoch 21/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2237 - acc: 0.9663\n",
            "Epoch 22/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2220 - acc: 0.9562\n",
            "Epoch 23/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2181 - acc: 0.9630\n",
            "Epoch 24/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2162 - acc: 0.9663\n",
            "Epoch 25/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2141 - acc: 0.9562\n",
            "Epoch 26/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2130 - acc: 0.9596\n",
            "Epoch 27/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2107 - acc: 0.9596\n",
            "Epoch 28/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2077 - acc: 0.9663\n",
            "Epoch 29/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2075 - acc: 0.9630\n",
            "Epoch 30/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2046 - acc: 0.9697\n",
            "Epoch 31/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2026 - acc: 0.9630\n",
            "Epoch 32/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.2009 - acc: 0.9630\n",
            "Epoch 33/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1983 - acc: 0.9663\n",
            "Epoch 34/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1978 - acc: 0.9630\n",
            "Epoch 35/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1953 - acc: 0.9697\n",
            "Epoch 36/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1933 - acc: 0.9663\n",
            "Epoch 37/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1915 - acc: 0.9663\n",
            "Epoch 38/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1895 - acc: 0.9663\n",
            "Epoch 39/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1882 - acc: 0.9663\n",
            "Epoch 40/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1880 - acc: 0.9697\n",
            "Epoch 41/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1841 - acc: 0.9663\n",
            "Epoch 42/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1835 - acc: 0.9663\n",
            "Epoch 43/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1825 - acc: 0.9630\n",
            "Epoch 44/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1793 - acc: 0.9663\n",
            "Epoch 45/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1784 - acc: 0.9731\n",
            "Epoch 46/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1766 - acc: 0.9697\n",
            "Epoch 47/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1758 - acc: 0.9663\n",
            "Epoch 48/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1746 - acc: 0.9697\n",
            "Epoch 49/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1719 - acc: 0.9697\n",
            "Epoch 50/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1720 - acc: 0.9630\n",
            "Epoch 51/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1683 - acc: 0.9697\n",
            "Epoch 52/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1684 - acc: 0.9697\n",
            "Epoch 53/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1666 - acc: 0.9697\n",
            "Epoch 54/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1652 - acc: 0.9731\n",
            "Epoch 55/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1634 - acc: 0.9697\n",
            "Epoch 56/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1623 - acc: 0.9697\n",
            "Epoch 57/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1625 - acc: 0.9731\n",
            "Epoch 58/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1598 - acc: 0.9697\n",
            "Epoch 59/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1584 - acc: 0.9697\n",
            "Epoch 60/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1570 - acc: 0.9731\n",
            "Epoch 61/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1560 - acc: 0.9764\n",
            "Epoch 62/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1548 - acc: 0.9697\n",
            "Epoch 63/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1548 - acc: 0.9731\n",
            "Epoch 64/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1528 - acc: 0.9731\n",
            "Epoch 65/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1514 - acc: 0.9764\n",
            "Epoch 66/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1503 - acc: 0.9731\n",
            "Epoch 67/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1486 - acc: 0.9731\n",
            "Epoch 68/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1482 - acc: 0.9764\n",
            "Epoch 69/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1475 - acc: 0.9731\n",
            "Epoch 70/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1466 - acc: 0.9697\n",
            "Epoch 71/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1442 - acc: 0.9764\n",
            "Epoch 72/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1432 - acc: 0.9731\n",
            "Epoch 73/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1425 - acc: 0.9731\n",
            "Epoch 74/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1413 - acc: 0.9764\n",
            "Epoch 75/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1402 - acc: 0.9798\n",
            "Epoch 76/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1409 - acc: 0.9731\n",
            "Epoch 77/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1407 - acc: 0.9731\n",
            "Epoch 78/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1383 - acc: 0.9731\n",
            "Epoch 79/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1372 - acc: 0.9731\n",
            "Epoch 80/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1353 - acc: 0.9764\n",
            "Epoch 81/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1352 - acc: 0.9764\n",
            "Epoch 82/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1337 - acc: 0.9697\n",
            "Epoch 83/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1324 - acc: 0.9798\n",
            "Epoch 84/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1316 - acc: 0.9731\n",
            "Epoch 85/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1306 - acc: 0.9764\n",
            "Epoch 86/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1305 - acc: 0.9764\n",
            "Epoch 87/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1300 - acc: 0.9731\n",
            "Epoch 88/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1284 - acc: 0.9764\n",
            "Epoch 89/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1275 - acc: 0.9764\n",
            "Epoch 90/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1268 - acc: 0.9764\n",
            "Epoch 91/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1262 - acc: 0.9798\n",
            "Epoch 92/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1253 - acc: 0.9798\n",
            "Epoch 93/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1240 - acc: 0.9764\n",
            "Epoch 94/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1233 - acc: 0.9764\n",
            "Epoch 95/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1234 - acc: 0.9731\n",
            "Epoch 96/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1212 - acc: 0.9798\n",
            "Epoch 97/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1214 - acc: 0.9764\n",
            "Epoch 98/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1215 - acc: 0.9731\n",
            "Epoch 99/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1193 - acc: 0.9798\n",
            "Epoch 100/100\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.1195 - acc: 0.9764\n",
            "51/51 [==============================] - 0s 307us/step\n",
            "Epoch 1/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1129 - acc: 0.9804\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1105 - acc: 0.9804\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1092 - acc: 0.9837\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1085 - acc: 0.9902\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1078 - acc: 0.9902\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1075 - acc: 0.9837\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1064 - acc: 0.9869\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1075 - acc: 0.9771\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1046 - acc: 0.9837\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1042 - acc: 0.9902\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1033 - acc: 0.9804\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1028 - acc: 0.9902\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1014 - acc: 0.9902\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1012 - acc: 0.9771\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1003 - acc: 0.9837\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.1008 - acc: 0.9804\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0994 - acc: 0.9902\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0970 - acc: 0.9902\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0980 - acc: 0.9804\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0963 - acc: 0.9869\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0952 - acc: 0.9902\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0946 - acc: 0.9902\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0939 - acc: 0.9869\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0934 - acc: 0.9869\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0930 - acc: 0.9837\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0945 - acc: 0.9837\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0931 - acc: 0.9935\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9804\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0914 - acc: 0.9837\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0907 - acc: 0.9869\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0888 - acc: 0.9902\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0887 - acc: 0.9902\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0890 - acc: 0.9804\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0877 - acc: 0.9869\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0867 - acc: 0.9869\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0860 - acc: 0.9837\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0853 - acc: 0.9902\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0854 - acc: 0.9902\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0841 - acc: 0.9902\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0838 - acc: 0.9869\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0828 - acc: 0.9902\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0823 - acc: 0.9935\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0830 - acc: 0.9869\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0817 - acc: 0.9902\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0807 - acc: 0.9902\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0810 - acc: 0.9902\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0799 - acc: 0.9902\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0792 - acc: 0.9902\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0795 - acc: 0.9837\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0779 - acc: 0.9935\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0783 - acc: 0.9935\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0787 - acc: 0.9902\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0774 - acc: 0.9935\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0769 - acc: 0.9837\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0767 - acc: 0.9869\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0761 - acc: 0.9902\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0758 - acc: 0.9869\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0756 - acc: 0.9902\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0741 - acc: 0.9902\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0735 - acc: 0.9902\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0742 - acc: 0.9837\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0729 - acc: 0.9902\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0722 - acc: 0.9902\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0724 - acc: 0.9902\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0717 - acc: 0.9935\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0710 - acc: 0.9935\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0713 - acc: 0.9869\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0710 - acc: 0.9935\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0700 - acc: 0.9902\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0709 - acc: 0.9869\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0688 - acc: 0.9935\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0687 - acc: 0.9935\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0680 - acc: 0.9902\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0679 - acc: 0.9935\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0680 - acc: 0.9935\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0668 - acc: 0.9935\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0670 - acc: 0.9869\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0672 - acc: 0.9935\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0663 - acc: 0.9869\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0664 - acc: 0.9902\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0653 - acc: 0.9902\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0650 - acc: 0.9902\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0658 - acc: 0.9935\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0662 - acc: 0.9869\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0635 - acc: 0.9902\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0640 - acc: 0.9935\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0632 - acc: 0.9935\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0633 - acc: 0.9902\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0634 - acc: 0.9935\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0625 - acc: 0.9902\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0621 - acc: 0.9902\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0621 - acc: 0.9869\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0610 - acc: 0.9935\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0621 - acc: 0.9869\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0594 - acc: 0.9935\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0604 - acc: 0.9935\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0600 - acc: 0.9935\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0607 - acc: 0.9935\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0599 - acc: 0.9902\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.0587 - acc: 0.9935\n",
            "48/48 [==============================] - 0s 142us/step\n",
            "Finished cross-valiation. Took 0.6 mintues.\n",
            "Mean Accuracy: 96.21%, Standard Deviation: 0.84%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9621459794979469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "LzC2z1JMyuv5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "api_token = {\"username\":\"georgeliu\",\"key\":\"API_KEY\"}\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!kaggle config path -p /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwRIfdxNJ6oM",
        "colab_type": "code",
        "outputId": "662bf41d-15a4-4b9c-cab7-03bd0b897651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "pima = pd.read_csv(\"/content/pima-indians-diabetes.csv\", header=None)\n",
        "pima.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1   2   3    4     5      6   7  8\n",
              "0  6  148  72  35    0  33.6  0.627  50  1\n",
              "1  1   85  66  29    0  26.6  0.351  31  0\n",
              "2  8  183  64   0    0  23.3  0.672  32  1\n",
              "3  1   89  66  23   94  28.1  0.167  21  0\n",
              "4  0  137  40  35  168  43.1  2.288  33  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "eJ-kaPbGKG7B",
        "colab_type": "code",
        "outputId": "7405ac1e-822e-4287-fdff-0564ffd6c0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_pima, y_pima = pima.values[:, 0:8], pima.values[:, 8]\n",
        "print(X_pima.shape, y_pima.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 8) (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3QbFJkQVK4tQ",
        "colab_type": "code",
        "outputId": "9c9a47ca-862d-48ca-dcd7-dc92b21dbc2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "input_dim = 8\n",
        "num_layers = 2\n",
        "num_units = (8, 1) \n",
        "activation = 'relu'\n",
        "activation_out = 'sigmoid'\n",
        "loss = 'binary_crossentropy'\n",
        "initializer = 'random_uniform'\n",
        "optimizer = 'adam'\n",
        "learning_rate = 0.001\n",
        "metrics = ['accuracy']\n",
        "epochs = 10\n",
        "batch_size = 5\n",
        "one_hot = False\n",
        "\n",
        "\n",
        "model = SequentialModel(input_dim=input_dim, \n",
        "                        num_layers=num_layers, \n",
        "                        num_units=num_units,\n",
        "                        activation=activation, \n",
        "                        activation_out=activation_out, \n",
        "                        loss=loss, \n",
        "                        initializer=initializer, \n",
        "                        optimizer=optimizer, \n",
        "                        learning_rate=learning_rate, \n",
        "                        metrics=metrics, \n",
        "                        epochs=epochs, \n",
        "                        batch_size=batch_size, \n",
        "                        one_hot=one_hot)\n",
        "\n",
        "model.build_model()\n",
        "model.evaluate_model(X_pima, y_pima)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6757 - acc: 0.6517\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 0s 940us/step - loss: 0.6604 - acc: 0.6438\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 0s 948us/step - loss: 0.6500 - acc: 0.6380\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6420 - acc: 0.6497\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6320 - acc: 0.6399\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6238 - acc: 0.6536\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6227 - acc: 0.6810\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6169 - acc: 0.6634\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6117 - acc: 0.6791\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6120 - acc: 0.6732\n",
            "257/257 [==============================] - 0s 258us/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6169 - acc: 0.6797\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6129 - acc: 0.6621\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6125 - acc: 0.6621\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6060 - acc: 0.6777\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6029 - acc: 0.6836\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5957 - acc: 0.6973\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5978 - acc: 0.6992\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6024 - acc: 0.6934\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5904 - acc: 0.7188\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5841 - acc: 0.7148\n",
            "256/256 [==============================] - 0s 68us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5972 - acc: 0.6842\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5909 - acc: 0.6764\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5920 - acc: 0.6842\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6040 - acc: 0.6881\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5964 - acc: 0.6745\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5911 - acc: 0.6881\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5862 - acc: 0.6901\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5812 - acc: 0.7173\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5857 - acc: 0.6842\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5930 - acc: 0.6979\n",
            "255/255 [==============================] - 0s 72us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 68.11%, Standard Deviation: 2.29%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6810626389393925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "2VnF5lzmLISj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "width = [8, 16, 32, 64]\n",
        "depth = [2, 4, 8, 16]\n",
        "loss = ['binary_crossentropy', 'categorical_crossentropy', 'sparse_categorical_crossentropy']\n",
        "initializer = ['random_uniform', 'random_normal', 'glorot_normal', 'glorot_uniform']\n",
        "learning_rate = [0.001, 0.01, 0.1, 1]\n",
        "optimizer = ['adam', 'adagrad', 'sgd', 'rmsprop']\n",
        "epochs = [10, 20, 40, 100]\n",
        "batch_size = [1, 5, 10, 15]\n",
        "\n",
        "\n",
        "tuning_options = {'width': width,\n",
        "                  'depth': depth, \n",
        "                  'loss': loss, \n",
        "                  'initializer': initializer, \n",
        "                  'optimizer': optimizer, \n",
        "                  'learning_rate': learning_rate,\n",
        "                  'epochs': epochs, \n",
        "                  'batch_size': batch_size}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cf3kbnDie18w",
        "colab_type": "code",
        "outputId": "8b6a59b6-79d5-4a4d-9511-3131e29f58b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48025
        }
      },
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for parameter, options in tuning_options.items():\n",
        "  \n",
        "  results[parameter] = {}\n",
        "  \n",
        "  input_dim = 8\n",
        "  num_layers = 2\n",
        "  num_units = (8, 1) \n",
        "  activation = 'relu'\n",
        "  activation_out = 'sigmoid'\n",
        "  loss = 'binary_crossentropy'\n",
        "  initializer = 'random_uniform'\n",
        "  learning_rate = 0.001\n",
        "  optimizer = 'adam'\n",
        "  metrics = ['accuracy']\n",
        "  epochs = 10\n",
        "  batch_size = 5\n",
        "  one_hot = False\n",
        "\n",
        "  for option in options:\n",
        "    \n",
        "    if parameter == 'width':\n",
        "      num_units = (option, 1)\n",
        "    elif parameter == 'depth':\n",
        "      num_layers = option\n",
        "    elif parameter == 'loss':\n",
        "      loss = option\n",
        "    elif parameter == 'initializer':\n",
        "      initializer = option\n",
        "    elif parameter == 'optimizer':\n",
        "      optimizer = option\n",
        "    elif parameter == 'learning_rate':\n",
        "      learning_rate = option\n",
        "    elif parameter == 'epochs':\n",
        "      epochs = option\n",
        "    else:\n",
        "      batch_size = option\n",
        "    \n",
        "    print(\"\\nEvaluating parameter \\\"{}\\\" using value \\\"{}\\\"...\".format(parameter, option))\n",
        "    \n",
        "    model = SequentialModel(input_dim=input_dim, \n",
        "                            num_layers=num_layers, \n",
        "                            num_units=num_units,\n",
        "                            activation=activation, \n",
        "                            activation_out=activation_out, \n",
        "                            loss=loss, \n",
        "                            initializer=initializer, \n",
        "                            optimizer=optimizer, \n",
        "                            learning_rate=learning_rate, \n",
        "                            metrics=metrics, \n",
        "                            epochs=epochs, \n",
        "                            batch_size=batch_size, \n",
        "                            one_hot=one_hot)\n",
        "    \n",
        "    try:\n",
        "      model.build_model()\n",
        "      result = model.evaluate_model(X_pima, y_pima)  \n",
        "      results[parameter][option] = result\n",
        "    except:\n",
        "      results[parameter][option] = 'NaN'\n",
        "      print('Error, skipped.')\n",
        "      pass\n",
        "\n",
        "# Save the dict    \n",
        "with open('cross_validation_results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating parameter \"width\" using value \"8\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6919 - acc: 0.5832\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6825 - acc: 0.6536\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6756 - acc: 0.6517\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6699 - acc: 0.6517\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6640 - acc: 0.6497\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6494 - acc: 0.6536\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6411 - acc: 0.6575\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6319 - acc: 0.6517\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6231 - acc: 0.6712\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6221 - acc: 0.6771\n",
            "257/257 [==============================] - 0s 311us/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6037 - acc: 0.6992\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6029 - acc: 0.6953\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5950 - acc: 0.6855\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5939 - acc: 0.6875\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5888 - acc: 0.7188\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5848 - acc: 0.7109\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5945 - acc: 0.7070\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5848 - acc: 0.7012\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5784 - acc: 0.7012\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5737 - acc: 0.7109\n",
            "256/256 [==============================] - 0s 70us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5901 - acc: 0.6940\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5889 - acc: 0.6920\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5909 - acc: 0.7037\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5816 - acc: 0.6940\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5795 - acc: 0.7115\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 997us/step - loss: 0.5789 - acc: 0.6940\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5770 - acc: 0.7037\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5737 - acc: 0.6998\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5756 - acc: 0.7057\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5713 - acc: 0.7076\n",
            "255/255 [==============================] - 0s 72us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 70.44%, Standard Deviation: 0.55%\n",
            "\n",
            "Evaluating parameter \"width\" using value \"16\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6677 - acc: 0.6419\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6509 - acc: 0.6712\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6406 - acc: 0.6536\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6280 - acc: 0.6673\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6214 - acc: 0.6732\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6183 - acc: 0.6830\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6099 - acc: 0.6810\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6172 - acc: 0.6791\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6071 - acc: 0.6771\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5993 - acc: 0.6849\n",
            "257/257 [==============================] - 0s 339us/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6027 - acc: 0.6934\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5983 - acc: 0.6816\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5922 - acc: 0.7031\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5918 - acc: 0.6914\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6040 - acc: 0.6602\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5887 - acc: 0.6973\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5805 - acc: 0.7090\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5737 - acc: 0.7129\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5764 - acc: 0.7188\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5757 - acc: 0.7051\n",
            "256/256 [==============================] - 0s 82us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5686 - acc: 0.7232\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5703 - acc: 0.7349\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5839 - acc: 0.6862\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5673 - acc: 0.7193\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5651 - acc: 0.7388\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5639 - acc: 0.7329\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5621 - acc: 0.7290\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5572 - acc: 0.7349\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5556 - acc: 0.7349\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5582 - acc: 0.7349\n",
            "255/255 [==============================] - 0s 66us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 71.62%, Standard Deviation: 2.70%\n",
            "\n",
            "Evaluating parameter \"width\" using value \"32\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6584 - acc: 0.6223\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6308 - acc: 0.6595\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6325 - acc: 0.6614\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6436 - acc: 0.6556\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6153 - acc: 0.6751\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6053 - acc: 0.6751\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6078 - acc: 0.6751\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6141 - acc: 0.6693\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5915 - acc: 0.6634\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5920 - acc: 0.6888\n",
            "257/257 [==============================] - 0s 429us/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5870 - acc: 0.7207\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5810 - acc: 0.7070\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5796 - acc: 0.7012\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5754 - acc: 0.7109\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5785 - acc: 0.6914\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5778 - acc: 0.7129\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5630 - acc: 0.7031\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5619 - acc: 0.7090\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5691 - acc: 0.7129\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5502 - acc: 0.7344\n",
            "256/256 [==============================] - 0s 70us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5643 - acc: 0.7310\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5689 - acc: 0.7388\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5601 - acc: 0.7232\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5594 - acc: 0.7193\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5615 - acc: 0.7290\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5427 - acc: 0.7524\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5624 - acc: 0.7290\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5436 - acc: 0.7505\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5477 - acc: 0.7310\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5478 - acc: 0.7290\n",
            "255/255 [==============================] - 0s 72us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 71.35%, Standard Deviation: 2.13%\n",
            "\n",
            "Evaluating parameter \"width\" using value \"64\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6693 - acc: 0.6282\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6494 - acc: 0.6380\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6362 - acc: 0.6556\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 997us/step - loss: 0.6294 - acc: 0.6497\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6056 - acc: 0.6732\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6078 - acc: 0.6791\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5934 - acc: 0.6771\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5869 - acc: 0.6947\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5935 - acc: 0.6830\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5938 - acc: 0.7065\n",
            "257/257 [==============================] - 0s 535us/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6059 - acc: 0.6973\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5871 - acc: 0.7266\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6032 - acc: 0.7012\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5916 - acc: 0.6914\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5801 - acc: 0.7051\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5892 - acc: 0.7148\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5746 - acc: 0.7285\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5608 - acc: 0.7188\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5662 - acc: 0.7266\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5922 - acc: 0.6934\n",
            "256/256 [==============================] - 0s 103us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5579 - acc: 0.7135\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5538 - acc: 0.7290\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5544 - acc: 0.7271\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5566 - acc: 0.7251\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5540 - acc: 0.7251\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5558 - acc: 0.7154\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5449 - acc: 0.7232\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5570 - acc: 0.7290\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5378 - acc: 0.7173\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5461 - acc: 0.7251\n",
            "255/255 [==============================] - 0s 77us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 69.67%, Standard Deviation: 2.08%\n",
            "\n",
            "Evaluating parameter \"depth\" using value \"2\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6796 - acc: 0.6086\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6459 - acc: 0.6595\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6374 - acc: 0.6497\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6198 - acc: 0.6634\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6104 - acc: 0.6869\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6142 - acc: 0.6654\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6019 - acc: 0.6869\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6010 - acc: 0.6928\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5977 - acc: 0.6947\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5970 - acc: 0.6849\n",
            "257/257 [==============================] - 0s 526us/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6252 - acc: 0.6777\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6177 - acc: 0.6836\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6124 - acc: 0.7012\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6143 - acc: 0.6875\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6134 - acc: 0.6777\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6114 - acc: 0.6953\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6068 - acc: 0.6914\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6029 - acc: 0.6953\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6094 - acc: 0.6836\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6044 - acc: 0.6836\n",
            "256/256 [==============================] - 0s 72us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5947 - acc: 0.6803\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5909 - acc: 0.7037\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5836 - acc: 0.6979\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5908 - acc: 0.6784\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5788 - acc: 0.7018\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5820 - acc: 0.6920\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5760 - acc: 0.7037\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5730 - acc: 0.7057\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5711 - acc: 0.7018\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5686 - acc: 0.6998\n",
            "255/255 [==============================] - 0s 71us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 66.81%, Standard Deviation: 4.05%\n",
            "\n",
            "Evaluating parameter \"depth\" using value \"4\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6851 - acc: 0.6438\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6651 - acc: 0.6517\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6537 - acc: 0.6517\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6488 - acc: 0.6517\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6399 - acc: 0.6517\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6341 - acc: 0.6517\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6216 - acc: 0.6634\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6054 - acc: 0.7162\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6037 - acc: 0.6947\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5970 - acc: 0.7045\n",
            "257/257 [==============================] - 0s 659us/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6065 - acc: 0.6777\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5886 - acc: 0.7090\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5867 - acc: 0.6836\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5865 - acc: 0.7012\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5859 - acc: 0.6973\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5801 - acc: 0.7070\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5847 - acc: 0.7090\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5845 - acc: 0.7070\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5765 - acc: 0.7129\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5728 - acc: 0.7188\n",
            "256/256 [==============================] - 0s 77us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5772 - acc: 0.7096\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5674 - acc: 0.7271\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5788 - acc: 0.7173\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5697 - acc: 0.7193\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5628 - acc: 0.7310\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5677 - acc: 0.7154\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5632 - acc: 0.7271\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5621 - acc: 0.7251\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5542 - acc: 0.7407\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5534 - acc: 0.7349\n",
            "255/255 [==============================] - 0s 82us/step\n",
            "Finished cross-valiation. Took 0.4 mintues.\n",
            "Mean Accuracy: 70.46%, Standard Deviation: 4.64%\n",
            "\n",
            "Evaluating parameter \"depth\" using value \"8\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6877 - acc: 0.6517\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6704 - acc: 0.6517\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6578 - acc: 0.6517\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6541 - acc: 0.6517\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6514 - acc: 0.6517\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6475 - acc: 0.6517\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6432 - acc: 0.6517\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6407 - acc: 0.6517\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6370 - acc: 0.6517\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: 0.6319 - acc: 0.6517\n",
            "257/257 [==============================] - 0s 851us/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6310 - acc: 0.6504\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6262 - acc: 0.6504\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6247 - acc: 0.6504\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6282 - acc: 0.6504\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6220 - acc: 0.6504\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6187 - acc: 0.6504\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6180 - acc: 0.6504\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6178 - acc: 0.6504\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6240 - acc: 0.6504\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 0.6217 - acc: 0.6504\n",
            "256/256 [==============================] - 0s 87us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6137 - acc: 0.6511\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6137 - acc: 0.6511\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6120 - acc: 0.6511\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6120 - acc: 0.6511\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6077 - acc: 0.6511\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6031 - acc: 0.6511\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6047 - acc: 0.6511\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6035 - acc: 0.6511\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6024 - acc: 0.6511\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 2ms/step - loss: 0.6025 - acc: 0.6511\n",
            "255/255 [==============================] - 0s 101us/step\n",
            "Finished cross-valiation. Took 0.5 mintues.\n",
            "Mean Accuracy: 65.10%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"depth\" using value \"16\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.6878 - acc: 0.6517\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6735 - acc: 0.6517\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6581 - acc: 0.6517\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6507 - acc: 0.6517\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6475 - acc: 0.6517\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6472 - acc: 0.6517\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6475 - acc: 0.6517\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6470 - acc: 0.6517\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6467 - acc: 0.6517\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6468 - acc: 0.6517\n",
            "257/257 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6477 - acc: 0.6504\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6477 - acc: 0.6504\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6477 - acc: 0.6504\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6479 - acc: 0.6504\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6481 - acc: 0.6504\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6476 - acc: 0.6504\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6479 - acc: 0.6504\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6476 - acc: 0.6504\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6475 - acc: 0.6504\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 2s 3ms/step - loss: 0.6475 - acc: 0.6504\n",
            "256/256 [==============================] - 0s 97us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6473 - acc: 0.6511\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6471 - acc: 0.6511\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6471 - acc: 0.6511\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6473 - acc: 0.6511\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6473 - acc: 0.6511\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6474 - acc: 0.6511\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6470 - acc: 0.6511\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6472 - acc: 0.6511\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6471 - acc: 0.6511\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 2s 3ms/step - loss: 0.6472 - acc: 0.6511\n",
            "255/255 [==============================] - 0s 100us/step\n",
            "Finished cross-valiation. Took 0.8 mintues.\n",
            "Mean Accuracy: 65.10%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"loss\" using value \"binary_crossentropy\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 3ms/step - loss: 0.6714 - acc: 0.6517\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6612 - acc: 0.6517\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6540 - acc: 0.6517\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6511 - acc: 0.6517\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6456 - acc: 0.6517\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6380 - acc: 0.6517\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6365 - acc: 0.6517\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6309 - acc: 0.6517\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6247 - acc: 0.6517\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6264 - acc: 0.6536\n",
            "257/257 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6131 - acc: 0.6504\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6072 - acc: 0.6504\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6038 - acc: 0.6504\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6106 - acc: 0.6504\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6082 - acc: 0.6504\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6035 - acc: 0.6504\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5931 - acc: 0.6504\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5962 - acc: 0.6504\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5922 - acc: 0.6504\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5932 - acc: 0.6523\n",
            "256/256 [==============================] - 0s 75us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6031 - acc: 0.6511\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5981 - acc: 0.6511\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5967 - acc: 0.6511\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5937 - acc: 0.6511\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6003 - acc: 0.6511\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5922 - acc: 0.6511\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5979 - acc: 0.6511\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5971 - acc: 0.6511\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5926 - acc: 0.6511\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5923 - acc: 0.6511\n",
            "255/255 [==============================] - 0s 88us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 65.24%, Standard Deviation: 0.21%\n",
            "\n",
            "Evaluating parameter \"loss\" using value \"categorical_crossentropy\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Error, skipped.\n",
            "\n",
            "Evaluating parameter \"loss\" using value \"sparse_categorical_crossentropy\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0020\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 0s 956us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 0s 914us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 0s 970us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 0s 924us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 0s 970us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 0s 894us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 0s 927us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 0s 944us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 0s 945us/step - loss: nan - acc: 0.0000e+00\n",
            "257/257 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 0s 910us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 0s 956us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 0s 896us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 0s 966us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 0s 911us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 0s 936us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 0s 919us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 0s 948us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 0s 916us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 0s 937us/step - loss: nan - acc: 0.0000e+00\n",
            "256/256 [==============================] - 0s 76us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 0s 881us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 0s 911us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 0s 970us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 0s 898us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 0s 947us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 0s 920us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 0s 958us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 0s 934us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 0s 924us/step - loss: nan - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 0s 890us/step - loss: nan - acc: 0.0000e+00\n",
            "255/255 [==============================] - 0s 77us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 0.00%, Standard Deviation: 0.00%\n",
            "\n",
            "Evaluating parameter \"initializer\" using value \"random_uniform\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 3ms/step - loss: 0.6679 - acc: 0.6399\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6455 - acc: 0.6634\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6340 - acc: 0.6634\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6257 - acc: 0.6751\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6222 - acc: 0.6693\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6198 - acc: 0.6947\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6040 - acc: 0.6849\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6043 - acc: 0.6908\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6048 - acc: 0.6732\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6097 - acc: 0.6928\n",
            "257/257 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6106 - acc: 0.6777\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.6719\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6055 - acc: 0.6836\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6097 - acc: 0.6680\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6001 - acc: 0.6777\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5979 - acc: 0.6875\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6027 - acc: 0.6855\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5974 - acc: 0.7031\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6000 - acc: 0.6699\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5915 - acc: 0.6973\n",
            "256/256 [==============================] - 0s 80us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5858 - acc: 0.7018\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5849 - acc: 0.7057\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5895 - acc: 0.7076\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5937 - acc: 0.6862\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5841 - acc: 0.7018\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5768 - acc: 0.6920\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5901 - acc: 0.6764\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5794 - acc: 0.6901\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5736 - acc: 0.7057\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5782 - acc: 0.7076\n",
            "255/255 [==============================] - 0s 86us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 69.15%, Standard Deviation: 2.95%\n",
            "\n",
            "Evaluating parameter \"initializer\" using value \"random_normal\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 1s 3ms/step - loss: 0.7220 - acc: 0.6341\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6753 - acc: 0.6517\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6632 - acc: 0.6556\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6502 - acc: 0.6360\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6416 - acc: 0.6556\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6391 - acc: 0.6517\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6363 - acc: 0.6536\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6245 - acc: 0.6614\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6226 - acc: 0.6693\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6203 - acc: 0.6791\n",
            "257/257 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6193 - acc: 0.6719\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6237 - acc: 0.6699\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6127 - acc: 0.6875\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6139 - acc: 0.6875\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6164 - acc: 0.6777\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6105 - acc: 0.6953\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6048 - acc: 0.7031\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6049 - acc: 0.6953\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6005 - acc: 0.7168\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5988 - acc: 0.6934\n",
            "256/256 [==============================] - 0s 78us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5773 - acc: 0.7115\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5814 - acc: 0.7154\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5853 - acc: 0.7076\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5741 - acc: 0.7193\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5735 - acc: 0.7135\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5831 - acc: 0.7076\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5761 - acc: 0.7057\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5751 - acc: 0.7310\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5719 - acc: 0.7251\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5720 - acc: 0.7212\n",
            "255/255 [==============================] - 0s 82us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 67.84%, Standard Deviation: 1.01%\n",
            "\n",
            "Evaluating parameter \"initializer\" using value \"glorot_normal\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 5.8670 - acc: 0.5127\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 5.6124 - acc: 0.5460\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 5.4119 - acc: 0.5362\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 5.2833 - acc: 0.5245\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 5.0920 - acc: 0.5284\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 4.6714 - acc: 0.5088\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 3.1408 - acc: 0.5186\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 1.6403 - acc: 0.5851\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 1.1593 - acc: 0.6047\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 1.0937 - acc: 0.5988\n",
            "257/257 [==============================] - 0s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 1.0314 - acc: 0.6191\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.9558 - acc: 0.6445\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.9679 - acc: 0.6270\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.8863 - acc: 0.6367\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.8704 - acc: 0.6348\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.8423 - acc: 0.6465\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.8400 - acc: 0.6621\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.8138 - acc: 0.6016\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.7820 - acc: 0.6426\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.7212 - acc: 0.6563\n",
            "256/256 [==============================] - 0s 84us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.7256 - acc: 0.6296\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6997 - acc: 0.6647\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6900 - acc: 0.6569\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.7057 - acc: 0.6686\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6668 - acc: 0.6667\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6792 - acc: 0.6803\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6616 - acc: 0.6881\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6621 - acc: 0.6862\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6360 - acc: 0.6959\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6454 - acc: 0.6823\n",
            "255/255 [==============================] - 0s 76us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 64.46%, Standard Deviation: 2.97%\n",
            "\n",
            "Evaluating parameter \"initializer\" using value \"glorot_uniform\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 5.6068 - acc: 0.6517\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 4.9916 - acc: 0.6536\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 1.7346 - acc: 0.5362\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 1.2391 - acc: 0.5636\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 1.1122 - acc: 0.5832\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 1.0179 - acc: 0.5910\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.9495 - acc: 0.6164\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.8979 - acc: 0.6223\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.8796 - acc: 0.5949\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.7927 - acc: 0.6164\n",
            "257/257 [==============================] - 0s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.7776 - acc: 0.6289\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.7426 - acc: 0.6543\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.7531 - acc: 0.6270\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.7131 - acc: 0.6582\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.7044 - acc: 0.6523\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6723 - acc: 0.6582\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6742 - acc: 0.6484\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.7050 - acc: 0.6543\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6591 - acc: 0.6738\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6473 - acc: 0.6680\n",
            "256/256 [==============================] - 0s 83us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6322 - acc: 0.6667\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6235 - acc: 0.6959\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6027 - acc: 0.6998\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6059 - acc: 0.6979\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5907 - acc: 0.7135\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5966 - acc: 0.6803\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5987 - acc: 0.7173\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6048 - acc: 0.7115\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6265 - acc: 0.6959\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5983 - acc: 0.6803\n",
            "255/255 [==============================] - 0s 95us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 65.64%, Standard Deviation: 3.45%\n",
            "\n",
            "Evaluating parameter \"optimizer\" using value \"adam\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6676 - acc: 0.6262\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6453 - acc: 0.6673\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6397 - acc: 0.6595\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6297 - acc: 0.6634\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6201 - acc: 0.6888\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6152 - acc: 0.6967\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6070 - acc: 0.6830\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6024 - acc: 0.6967\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6003 - acc: 0.6967\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5997 - acc: 0.6928\n",
            "257/257 [==============================] - 1s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6286 - acc: 0.6719\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6264 - acc: 0.6563\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6151 - acc: 0.6777\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6129 - acc: 0.6816\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6085 - acc: 0.6973\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6048 - acc: 0.6738\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6045 - acc: 0.6797\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6003 - acc: 0.6914\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6079 - acc: 0.6660\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5973 - acc: 0.6777\n",
            "256/256 [==============================] - 0s 80us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5988 - acc: 0.6862\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5986 - acc: 0.6764\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5869 - acc: 0.7037\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5942 - acc: 0.6784\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5843 - acc: 0.7037\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5848 - acc: 0.6998\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5801 - acc: 0.7057\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5798 - acc: 0.7135\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5780 - acc: 0.6940\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5741 - acc: 0.7037\n",
            "255/255 [==============================] - 0s 76us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 68.50%, Standard Deviation: 3.51%\n",
            "\n",
            "Evaluating parameter \"optimizer\" using value \"adagrad\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6675 - acc: 0.6419\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 984us/step - loss: 0.6540 - acc: 0.6497\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 984us/step - loss: 0.6494 - acc: 0.6477\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 0s 966us/step - loss: 0.6473 - acc: 0.6477\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6458 - acc: 0.6497\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 0s 959us/step - loss: 0.6445 - acc: 0.6517\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 0s 967us/step - loss: 0.6436 - acc: 0.6497\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 0s 955us/step - loss: 0.6429 - acc: 0.6517\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 980us/step - loss: 0.6422 - acc: 0.6497\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 0s 958us/step - loss: 0.6418 - acc: 0.6517\n",
            "257/257 [==============================] - 0s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 0s 974us/step - loss: 0.6474 - acc: 0.6484\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 0s 967us/step - loss: 0.6469 - acc: 0.6445\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 0s 964us/step - loss: 0.6466 - acc: 0.6465\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 0s 958us/step - loss: 0.6462 - acc: 0.6445\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 0s 970us/step - loss: 0.6458 - acc: 0.6465\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 0s 968us/step - loss: 0.6455 - acc: 0.6465\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 979us/step - loss: 0.6451 - acc: 0.6465\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 977us/step - loss: 0.6448 - acc: 0.6445\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 982us/step - loss: 0.6445 - acc: 0.6465\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 0s 962us/step - loss: 0.6442 - acc: 0.6465\n",
            "256/256 [==============================] - 0s 76us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 0s 953us/step - loss: 0.6446 - acc: 0.6472\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 0s 951us/step - loss: 0.6443 - acc: 0.6472\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 992us/step - loss: 0.6440 - acc: 0.6472\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 0s 973us/step - loss: 0.6438 - acc: 0.6472\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 0s 964us/step - loss: 0.6436 - acc: 0.6472\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 0s 930us/step - loss: 0.6433 - acc: 0.6472\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 989us/step - loss: 0.6431 - acc: 0.6472\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 0s 960us/step - loss: 0.6429 - acc: 0.6452\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 0s 969us/step - loss: 0.6427 - acc: 0.6472\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 0s 937us/step - loss: 0.6425 - acc: 0.6472\n",
            "255/255 [==============================] - 0s 76us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 65.11%, Standard Deviation: 0.69%\n",
            "\n",
            "Evaluating parameter \"optimizer\" using value \"sgd\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6797 - acc: 0.6204\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 0s 901us/step - loss: 0.6589 - acc: 0.6438\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 0s 893us/step - loss: 0.6520 - acc: 0.6477\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 0s 915us/step - loss: 0.6468 - acc: 0.6438\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 0s 923us/step - loss: 0.6437 - acc: 0.6614\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 0s 910us/step - loss: 0.6416 - acc: 0.6497\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 0s 913us/step - loss: 0.6348 - acc: 0.6634\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 0s 893us/step - loss: 0.6342 - acc: 0.6712\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 0s 935us/step - loss: 0.6368 - acc: 0.6614\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 0s 902us/step - loss: 0.6287 - acc: 0.6556\n",
            "257/257 [==============================] - 0s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 0s 911us/step - loss: 0.6346 - acc: 0.6641\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 0s 902us/step - loss: 0.6382 - acc: 0.6660\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 0s 950us/step - loss: 0.6350 - acc: 0.6523\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 0s 889us/step - loss: 0.6368 - acc: 0.6484\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 0s 945us/step - loss: 0.6305 - acc: 0.6523\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 0s 917us/step - loss: 0.6333 - acc: 0.6699\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 0s 941us/step - loss: 0.6315 - acc: 0.6641\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 0s 921us/step - loss: 0.6280 - acc: 0.6543\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 0s 972us/step - loss: 0.6316 - acc: 0.6660\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 0s 948us/step - loss: 0.6284 - acc: 0.6680\n",
            "256/256 [==============================] - 0s 79us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 0s 968us/step - loss: 0.6262 - acc: 0.6667\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 0s 899us/step - loss: 0.6183 - acc: 0.6862\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 0s 928us/step - loss: 0.6193 - acc: 0.6686\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 0s 905us/step - loss: 0.6150 - acc: 0.6823\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 0s 926us/step - loss: 0.6143 - acc: 0.6901\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 0s 917us/step - loss: 0.6128 - acc: 0.6823\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 0s 923us/step - loss: 0.6144 - acc: 0.6745\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 0s 960us/step - loss: 0.6118 - acc: 0.6823\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 0s 902us/step - loss: 0.6088 - acc: 0.6901\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 0s 959us/step - loss: 0.6115 - acc: 0.6823\n",
            "255/255 [==============================] - 0s 81us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 66.53%, Standard Deviation: 1.92%\n",
            "\n",
            "Evaluating parameter \"optimizer\" using value \"rmsprop\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 3ms/step - loss: 0.6893 - acc: 0.6282\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 993us/step - loss: 0.6727 - acc: 0.6438\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6659 - acc: 0.6497\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 999us/step - loss: 0.6588 - acc: 0.6517\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6531 - acc: 0.6477\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 995us/step - loss: 0.6450 - acc: 0.6556\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6384 - acc: 0.6595\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 0s 978us/step - loss: 0.6337 - acc: 0.6673\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6241 - acc: 0.6673\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 991us/step - loss: 0.6195 - acc: 0.6575\n",
            "257/257 [==============================] - 1s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 984us/step - loss: 0.6080 - acc: 0.6680\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6028 - acc: 0.6719\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 996us/step - loss: 0.6020 - acc: 0.6699\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5962 - acc: 0.6777\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5963 - acc: 0.6758\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5939 - acc: 0.6797\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5861 - acc: 0.6875\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5924 - acc: 0.6719\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 981us/step - loss: 0.5888 - acc: 0.6797\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5901 - acc: 0.6816\n",
            "256/256 [==============================] - 0s 90us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 994us/step - loss: 0.6087 - acc: 0.6706\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6048 - acc: 0.6803\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6133 - acc: 0.6628\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6047 - acc: 0.6745\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6060 - acc: 0.6745\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 988us/step - loss: 0.6065 - acc: 0.6647\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 985us/step - loss: 0.6037 - acc: 0.6784\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 990us/step - loss: 0.6082 - acc: 0.6745\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 990us/step - loss: 0.6026 - acc: 0.6745\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6045 - acc: 0.6803\n",
            "255/255 [==============================] - 0s 92us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 67.58%, Standard Deviation: 0.38%\n",
            "\n",
            "Evaluating parameter \"learning_rate\" using value \"0.001\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 4ms/step - loss: 0.6688 - acc: 0.6204\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6438 - acc: 0.6595\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6270 - acc: 0.6673\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6230 - acc: 0.6830\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6120 - acc: 0.6908\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6074 - acc: 0.6849\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5978 - acc: 0.6908\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5947 - acc: 0.6967\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5852 - acc: 0.7006\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5913 - acc: 0.7006\n",
            "257/257 [==============================] - 1s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6039 - acc: 0.6973\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6012 - acc: 0.7148\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5874 - acc: 0.7148\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5932 - acc: 0.6914\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5844 - acc: 0.7129\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5797 - acc: 0.7148\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5814 - acc: 0.7207\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5763 - acc: 0.7070\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5723 - acc: 0.7051\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5720 - acc: 0.7227\n",
            "256/256 [==============================] - 0s 78us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5885 - acc: 0.7037\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5823 - acc: 0.7193\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5716 - acc: 0.7173\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5715 - acc: 0.7271\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5740 - acc: 0.7251\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5737 - acc: 0.7232\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5641 - acc: 0.7349\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5722 - acc: 0.7232\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5643 - acc: 0.7232\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5672 - acc: 0.7388\n",
            "255/255 [==============================] - 0s 77us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 70.32%, Standard Deviation: 1.31%\n",
            "\n",
            "Evaluating parameter \"learning_rate\" using value \"0.01\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 4ms/step - loss: 0.6875 - acc: 0.6477\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6505 - acc: 0.6517\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6469 - acc: 0.6517\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6473 - acc: 0.6517\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6443 - acc: 0.6517\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6388 - acc: 0.6517\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6477 - acc: 0.6517\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6468 - acc: 0.6517\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6473 - acc: 0.6517\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6472 - acc: 0.6517\n",
            "257/257 [==============================] - 1s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6486 - acc: 0.6504\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6475 - acc: 0.6504\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6481 - acc: 0.6504\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6477 - acc: 0.6504\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6480 - acc: 0.6504\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6477 - acc: 0.6504\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6479 - acc: 0.6504\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6477 - acc: 0.6504\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6475 - acc: 0.6504\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6478 - acc: 0.6504\n",
            "256/256 [==============================] - 0s 89us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6483 - acc: 0.6511\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6478 - acc: 0.6511\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6471 - acc: 0.6511\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6474 - acc: 0.6511\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6476 - acc: 0.6511\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6474 - acc: 0.6511\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6478 - acc: 0.6511\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6474 - acc: 0.6511\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6481 - acc: 0.6511\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6476 - acc: 0.6511\n",
            "255/255 [==============================] - 0s 84us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 65.10%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"learning_rate\" using value \"0.1\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 4ms/step - loss: 0.7385 - acc: 0.6301\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6499 - acc: 0.6517\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6484 - acc: 0.6517\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6524 - acc: 0.6517\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6494 - acc: 0.6517\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6508 - acc: 0.6517\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6540 - acc: 0.6517\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6507 - acc: 0.6517\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6513 - acc: 0.6517\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6629 - acc: 0.6517\n",
            "257/257 [==============================] - 1s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6492 - acc: 0.6504\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6553 - acc: 0.6504\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6561 - acc: 0.6504\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6575 - acc: 0.6504\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6560 - acc: 0.6504\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6498 - acc: 0.6504\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6530 - acc: 0.6504\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6570 - acc: 0.6504\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6520 - acc: 0.6504\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6550 - acc: 0.6504\n",
            "256/256 [==============================] - 0s 87us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6486 - acc: 0.6511\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6553 - acc: 0.6511\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6540 - acc: 0.6511\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6529 - acc: 0.6511\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6551 - acc: 0.6511\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6530 - acc: 0.6511\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6541 - acc: 0.6511\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6518 - acc: 0.6511\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6528 - acc: 0.6511\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.6496 - acc: 0.6511\n",
            "255/255 [==============================] - 0s 78us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 65.10%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"learning_rate\" using value \"1\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 4ms/step - loss: 9.9144 - acc: 0.3757\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 10.3891 - acc: 0.3483\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 10.3891 - acc: 0.3483\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 10.3891 - acc: 0.3483\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 10.3891 - acc: 0.3483\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 10.3891 - acc: 0.3483\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 10.3891 - acc: 0.3483\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 10.3891 - acc: 0.3483\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 10.3891 - acc: 0.3483\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 10.3891 - acc: 0.3483\n",
            "257/257 [==============================] - 1s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 10.3688 - acc: 0.3496\n",
            "256/256 [==============================] - 0s 93us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 10.3796 - acc: 0.3489\n",
            "255/255 [==============================] - 0s 84us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 34.90%, Standard Deviation: 0.10%\n",
            "\n",
            "Evaluating parameter \"epochs\" using value \"10\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 4ms/step - loss: 0.6753 - acc: 0.6067\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6475 - acc: 0.6517\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6328 - acc: 0.6575\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6218 - acc: 0.6614\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6221 - acc: 0.6497\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6044 - acc: 0.6830\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6048 - acc: 0.6810\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6012 - acc: 0.6849\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5936 - acc: 0.6830\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5841 - acc: 0.7025\n",
            "257/257 [==============================] - 1s 2ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6120 - acc: 0.6953\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6071 - acc: 0.6875\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5989 - acc: 0.6895\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6035 - acc: 0.6895\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6013 - acc: 0.6836\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5975 - acc: 0.6953\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6007 - acc: 0.7070\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.6006 - acc: 0.6934\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5999 - acc: 0.6992\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5977 - acc: 0.7031\n",
            "256/256 [==============================] - 0s 85us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5884 - acc: 0.6803\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5812 - acc: 0.7037\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5793 - acc: 0.7018\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5819 - acc: 0.7018\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5705 - acc: 0.7018\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5865 - acc: 0.6998\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5744 - acc: 0.6920\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5736 - acc: 0.7057\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5711 - acc: 0.6979\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5701 - acc: 0.7037\n",
            "255/255 [==============================] - 0s 86us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 70.58%, Standard Deviation: 0.94%\n",
            "\n",
            "Evaluating parameter \"epochs\" using value \"20\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/20\n",
            "511/511 [==============================] - 2s 4ms/step - loss: 0.6700 - acc: 0.6438\n",
            "Epoch 2/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6310 - acc: 0.6693\n",
            "Epoch 3/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6177 - acc: 0.6751\n",
            "Epoch 4/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6084 - acc: 0.6908\n",
            "Epoch 5/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5991 - acc: 0.7045\n",
            "Epoch 6/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6015 - acc: 0.6928\n",
            "Epoch 7/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5861 - acc: 0.7182\n",
            "Epoch 8/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5759 - acc: 0.7123\n",
            "Epoch 9/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5756 - acc: 0.7202\n",
            "Epoch 10/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5887 - acc: 0.7143\n",
            "Epoch 11/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5702 - acc: 0.7182\n",
            "Epoch 12/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5627 - acc: 0.7280\n",
            "Epoch 13/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5779 - acc: 0.7045\n",
            "Epoch 14/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5554 - acc: 0.7182\n",
            "Epoch 15/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5660 - acc: 0.7182\n",
            "Epoch 16/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5611 - acc: 0.7456\n",
            "Epoch 17/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5603 - acc: 0.7319\n",
            "Epoch 18/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5560 - acc: 0.7299\n",
            "Epoch 19/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5621 - acc: 0.7162\n",
            "Epoch 20/20\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5579 - acc: 0.7397\n",
            "257/257 [==============================] - 1s 3ms/step\n",
            "Epoch 1/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5997 - acc: 0.6934\n",
            "Epoch 2/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5899 - acc: 0.6895\n",
            "Epoch 3/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5811 - acc: 0.6992\n",
            "Epoch 4/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5887 - acc: 0.6895\n",
            "Epoch 5/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5841 - acc: 0.7090\n",
            "Epoch 6/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5803 - acc: 0.6934\n",
            "Epoch 7/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5755 - acc: 0.7227\n",
            "Epoch 8/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5723 - acc: 0.6934\n",
            "Epoch 9/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5689 - acc: 0.7285\n",
            "Epoch 10/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5705 - acc: 0.7109\n",
            "Epoch 11/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5648 - acc: 0.7227\n",
            "Epoch 12/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5749 - acc: 0.7266\n",
            "Epoch 13/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5665 - acc: 0.7168\n",
            "Epoch 14/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5723 - acc: 0.6914\n",
            "Epoch 15/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5595 - acc: 0.7227\n",
            "Epoch 16/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5594 - acc: 0.7227\n",
            "Epoch 17/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5609 - acc: 0.7207\n",
            "Epoch 18/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5640 - acc: 0.7324\n",
            "Epoch 19/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5597 - acc: 0.7129\n",
            "Epoch 20/20\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5600 - acc: 0.7246\n",
            "256/256 [==============================] - 0s 79us/step\n",
            "Epoch 1/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5759 - acc: 0.7057\n",
            "Epoch 2/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5741 - acc: 0.7193\n",
            "Epoch 3/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5703 - acc: 0.7212\n",
            "Epoch 4/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5662 - acc: 0.6920\n",
            "Epoch 5/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5678 - acc: 0.7173\n",
            "Epoch 6/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5616 - acc: 0.7290\n",
            "Epoch 7/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5656 - acc: 0.7349\n",
            "Epoch 8/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5609 - acc: 0.7154\n",
            "Epoch 9/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5743 - acc: 0.7037\n",
            "Epoch 10/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5588 - acc: 0.7271\n",
            "Epoch 11/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5705 - acc: 0.7037\n",
            "Epoch 12/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5562 - acc: 0.7193\n",
            "Epoch 13/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5601 - acc: 0.7251\n",
            "Epoch 14/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5636 - acc: 0.7251\n",
            "Epoch 15/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5626 - acc: 0.7193\n",
            "Epoch 16/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5523 - acc: 0.7290\n",
            "Epoch 17/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5493 - acc: 0.7154\n",
            "Epoch 18/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5509 - acc: 0.7251\n",
            "Epoch 19/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5555 - acc: 0.7290\n",
            "Epoch 20/20\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5587 - acc: 0.7271\n",
            "255/255 [==============================] - 0s 92us/step\n",
            "Finished cross-valiation. Took 0.6 mintues.\n",
            "Mean Accuracy: 69.15%, Standard Deviation: 4.22%\n",
            "\n",
            "Evaluating parameter \"epochs\" using value \"40\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/40\n",
            "511/511 [==============================] - 2s 4ms/step - loss: 0.6780 - acc: 0.6184\n",
            "Epoch 2/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6580 - acc: 0.6575\n",
            "Epoch 3/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6531 - acc: 0.6497\n",
            "Epoch 4/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6426 - acc: 0.6536\n",
            "Epoch 5/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6483 - acc: 0.6497\n",
            "Epoch 6/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6344 - acc: 0.6575\n",
            "Epoch 7/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6238 - acc: 0.6751\n",
            "Epoch 8/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6246 - acc: 0.6693\n",
            "Epoch 9/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6290 - acc: 0.6556\n",
            "Epoch 10/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6129 - acc: 0.6791\n",
            "Epoch 11/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6282 - acc: 0.6830\n",
            "Epoch 12/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6131 - acc: 0.6732\n",
            "Epoch 13/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6028 - acc: 0.6947\n",
            "Epoch 14/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6042 - acc: 0.6673\n",
            "Epoch 15/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6052 - acc: 0.6849\n",
            "Epoch 16/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6016 - acc: 0.6869\n",
            "Epoch 17/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6016 - acc: 0.6791\n",
            "Epoch 18/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5946 - acc: 0.6967\n",
            "Epoch 19/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5958 - acc: 0.6947\n",
            "Epoch 20/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5966 - acc: 0.6712\n",
            "Epoch 21/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5869 - acc: 0.6830\n",
            "Epoch 22/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5871 - acc: 0.6869\n",
            "Epoch 23/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5831 - acc: 0.7006\n",
            "Epoch 24/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5911 - acc: 0.6869\n",
            "Epoch 25/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5892 - acc: 0.6928\n",
            "Epoch 26/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5862 - acc: 0.7065\n",
            "Epoch 27/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5809 - acc: 0.7025\n",
            "Epoch 28/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5801 - acc: 0.7006\n",
            "Epoch 29/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5773 - acc: 0.7006\n",
            "Epoch 30/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5800 - acc: 0.6908\n",
            "Epoch 31/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5797 - acc: 0.7045\n",
            "Epoch 32/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5765 - acc: 0.6986\n",
            "Epoch 33/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5732 - acc: 0.7182\n",
            "Epoch 34/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5717 - acc: 0.7065\n",
            "Epoch 35/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5716 - acc: 0.7084\n",
            "Epoch 36/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5709 - acc: 0.7084\n",
            "Epoch 37/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5743 - acc: 0.6849\n",
            "Epoch 38/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5645 - acc: 0.7182\n",
            "Epoch 39/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5731 - acc: 0.7045\n",
            "Epoch 40/40\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5638 - acc: 0.7084\n",
            "257/257 [==============================] - 1s 3ms/step\n",
            "Epoch 1/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5620 - acc: 0.7461\n",
            "Epoch 2/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5642 - acc: 0.7246\n",
            "Epoch 3/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5580 - acc: 0.7324\n",
            "Epoch 4/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5547 - acc: 0.7363\n",
            "Epoch 5/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5577 - acc: 0.7324\n",
            "Epoch 6/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5511 - acc: 0.7500\n",
            "Epoch 7/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5551 - acc: 0.7383\n",
            "Epoch 8/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5474 - acc: 0.7422\n",
            "Epoch 9/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5484 - acc: 0.7422\n",
            "Epoch 10/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5531 - acc: 0.7480\n",
            "Epoch 11/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5490 - acc: 0.7402\n",
            "Epoch 12/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5463 - acc: 0.7480\n",
            "Epoch 13/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5416 - acc: 0.7422\n",
            "Epoch 14/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5485 - acc: 0.7441\n",
            "Epoch 15/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5439 - acc: 0.7344\n",
            "Epoch 16/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5464 - acc: 0.7422\n",
            "Epoch 17/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5463 - acc: 0.7285\n",
            "Epoch 18/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5446 - acc: 0.7363\n",
            "Epoch 19/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5444 - acc: 0.7402\n",
            "Epoch 20/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5435 - acc: 0.7441\n",
            "Epoch 21/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5409 - acc: 0.7383\n",
            "Epoch 22/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5404 - acc: 0.7539\n",
            "Epoch 23/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5432 - acc: 0.7402\n",
            "Epoch 24/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5463 - acc: 0.7363\n",
            "Epoch 25/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5379 - acc: 0.7422\n",
            "Epoch 26/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5413 - acc: 0.7480\n",
            "Epoch 27/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5466 - acc: 0.7500\n",
            "Epoch 28/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5393 - acc: 0.7598\n",
            "Epoch 29/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5419 - acc: 0.7363\n",
            "Epoch 30/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5370 - acc: 0.7383\n",
            "Epoch 31/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5377 - acc: 0.7578\n",
            "Epoch 32/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5383 - acc: 0.7520\n",
            "Epoch 33/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5420 - acc: 0.7363\n",
            "Epoch 34/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5384 - acc: 0.7383\n",
            "Epoch 35/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5416 - acc: 0.7402\n",
            "Epoch 36/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5361 - acc: 0.7363\n",
            "Epoch 37/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5452 - acc: 0.7324\n",
            "Epoch 38/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5380 - acc: 0.7363\n",
            "Epoch 39/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5412 - acc: 0.7441\n",
            "Epoch 40/40\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5385 - acc: 0.7461\n",
            "256/256 [==============================] - 0s 84us/step\n",
            "Epoch 1/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5288 - acc: 0.7505\n",
            "Epoch 2/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5225 - acc: 0.7563\n",
            "Epoch 3/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5293 - acc: 0.7446\n",
            "Epoch 4/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5223 - acc: 0.7446\n",
            "Epoch 5/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5304 - acc: 0.7485\n",
            "Epoch 6/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5153 - acc: 0.7700\n",
            "Epoch 7/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5210 - acc: 0.7641\n",
            "Epoch 8/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5226 - acc: 0.7680\n",
            "Epoch 9/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5198 - acc: 0.7427\n",
            "Epoch 10/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5115 - acc: 0.7739\n",
            "Epoch 11/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5083 - acc: 0.7680\n",
            "Epoch 12/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5158 - acc: 0.7563\n",
            "Epoch 13/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5149 - acc: 0.7700\n",
            "Epoch 14/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5154 - acc: 0.7661\n",
            "Epoch 15/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5210 - acc: 0.7641\n",
            "Epoch 16/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5075 - acc: 0.7583\n",
            "Epoch 17/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5114 - acc: 0.7583\n",
            "Epoch 18/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5189 - acc: 0.7466\n",
            "Epoch 19/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5188 - acc: 0.7524\n",
            "Epoch 20/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5078 - acc: 0.7466\n",
            "Epoch 21/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5039 - acc: 0.7563\n",
            "Epoch 22/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5119 - acc: 0.7700\n",
            "Epoch 23/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5171 - acc: 0.7427\n",
            "Epoch 24/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5079 - acc: 0.7602\n",
            "Epoch 25/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5128 - acc: 0.7602\n",
            "Epoch 26/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5124 - acc: 0.7641\n",
            "Epoch 27/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5015 - acc: 0.7641\n",
            "Epoch 28/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5142 - acc: 0.7602\n",
            "Epoch 29/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5137 - acc: 0.7641\n",
            "Epoch 30/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4966 - acc: 0.7680\n",
            "Epoch 31/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5067 - acc: 0.7446\n",
            "Epoch 32/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4990 - acc: 0.7583\n",
            "Epoch 33/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5034 - acc: 0.7700\n",
            "Epoch 34/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5062 - acc: 0.7622\n",
            "Epoch 35/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4984 - acc: 0.7680\n",
            "Epoch 36/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4964 - acc: 0.7719\n",
            "Epoch 37/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5043 - acc: 0.7602\n",
            "Epoch 38/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5055 - acc: 0.7661\n",
            "Epoch 39/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5057 - acc: 0.7407\n",
            "Epoch 40/40\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5005 - acc: 0.7641\n",
            "255/255 [==============================] - 0s 83us/step\n",
            "Finished cross-valiation. Took 1.2 mintues.\n",
            "Mean Accuracy: 74.35%, Standard Deviation: 1.64%\n",
            "\n",
            "Evaluating parameter \"epochs\" using value \"100\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/100\n",
            "511/511 [==============================] - 2s 4ms/step - loss: 0.6707 - acc: 0.6282\n",
            "Epoch 2/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6566 - acc: 0.6458\n",
            "Epoch 3/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6428 - acc: 0.6497\n",
            "Epoch 4/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6334 - acc: 0.6634\n",
            "Epoch 5/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6224 - acc: 0.6869\n",
            "Epoch 6/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6147 - acc: 0.6712\n",
            "Epoch 7/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6149 - acc: 0.6595\n",
            "Epoch 8/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6077 - acc: 0.6928\n",
            "Epoch 9/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6013 - acc: 0.6849\n",
            "Epoch 10/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5972 - acc: 0.6947\n",
            "Epoch 11/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5893 - acc: 0.6947\n",
            "Epoch 12/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5838 - acc: 0.6908\n",
            "Epoch 13/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5870 - acc: 0.6986\n",
            "Epoch 14/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6020 - acc: 0.6654\n",
            "Epoch 15/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5822 - acc: 0.7025\n",
            "Epoch 16/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5749 - acc: 0.6986\n",
            "Epoch 17/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5752 - acc: 0.7162\n",
            "Epoch 18/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5716 - acc: 0.7241\n",
            "Epoch 19/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5689 - acc: 0.7025\n",
            "Epoch 20/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5729 - acc: 0.7123\n",
            "Epoch 21/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5733 - acc: 0.7045\n",
            "Epoch 22/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5725 - acc: 0.6986\n",
            "Epoch 23/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5693 - acc: 0.7123\n",
            "Epoch 24/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5634 - acc: 0.7397\n",
            "Epoch 25/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5651 - acc: 0.7123\n",
            "Epoch 26/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5604 - acc: 0.7202\n",
            "Epoch 27/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5559 - acc: 0.7358\n",
            "Epoch 28/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5605 - acc: 0.7339\n",
            "Epoch 29/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5683 - acc: 0.7143\n",
            "Epoch 30/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5621 - acc: 0.7221\n",
            "Epoch 31/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5540 - acc: 0.7241\n",
            "Epoch 32/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5534 - acc: 0.7417\n",
            "Epoch 33/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5521 - acc: 0.7319\n",
            "Epoch 34/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5623 - acc: 0.7162\n",
            "Epoch 35/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5529 - acc: 0.7241\n",
            "Epoch 36/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5521 - acc: 0.7221\n",
            "Epoch 37/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5498 - acc: 0.7221\n",
            "Epoch 38/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5450 - acc: 0.7299\n",
            "Epoch 39/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5477 - acc: 0.7319\n",
            "Epoch 40/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5554 - acc: 0.7162\n",
            "Epoch 41/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5511 - acc: 0.7241\n",
            "Epoch 42/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5506 - acc: 0.7260\n",
            "Epoch 43/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5461 - acc: 0.7202\n",
            "Epoch 44/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5460 - acc: 0.7358\n",
            "Epoch 45/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5383 - acc: 0.7476\n",
            "Epoch 46/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5437 - acc: 0.7515\n",
            "Epoch 47/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5461 - acc: 0.7260\n",
            "Epoch 48/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5491 - acc: 0.7397\n",
            "Epoch 49/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5436 - acc: 0.7358\n",
            "Epoch 50/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5467 - acc: 0.7280\n",
            "Epoch 51/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5412 - acc: 0.7280\n",
            "Epoch 52/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5393 - acc: 0.7397\n",
            "Epoch 53/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5342 - acc: 0.7476\n",
            "Epoch 54/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5327 - acc: 0.7378\n",
            "Epoch 55/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5333 - acc: 0.7280\n",
            "Epoch 56/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5410 - acc: 0.7202\n",
            "Epoch 57/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5313 - acc: 0.7378\n",
            "Epoch 58/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5385 - acc: 0.7319\n",
            "Epoch 59/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5400 - acc: 0.7456\n",
            "Epoch 60/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5338 - acc: 0.7378\n",
            "Epoch 61/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5384 - acc: 0.7378\n",
            "Epoch 62/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5370 - acc: 0.7417\n",
            "Epoch 63/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5420 - acc: 0.7299\n",
            "Epoch 64/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5406 - acc: 0.7358\n",
            "Epoch 65/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5423 - acc: 0.7319\n",
            "Epoch 66/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5279 - acc: 0.7319\n",
            "Epoch 67/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5270 - acc: 0.7613\n",
            "Epoch 68/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5264 - acc: 0.7534\n",
            "Epoch 69/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5390 - acc: 0.7241\n",
            "Epoch 70/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5321 - acc: 0.7397\n",
            "Epoch 71/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5282 - acc: 0.7378\n",
            "Epoch 72/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5251 - acc: 0.7358\n",
            "Epoch 73/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5453 - acc: 0.7339\n",
            "Epoch 74/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5293 - acc: 0.7456\n",
            "Epoch 75/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5282 - acc: 0.7358\n",
            "Epoch 76/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5309 - acc: 0.7515\n",
            "Epoch 77/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5253 - acc: 0.7397\n",
            "Epoch 78/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5189 - acc: 0.7515\n",
            "Epoch 79/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5230 - acc: 0.7417\n",
            "Epoch 80/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5249 - acc: 0.7397\n",
            "Epoch 81/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5215 - acc: 0.7417\n",
            "Epoch 82/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5300 - acc: 0.7221\n",
            "Epoch 83/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5236 - acc: 0.7260\n",
            "Epoch 84/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5234 - acc: 0.7358\n",
            "Epoch 85/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5173 - acc: 0.7378\n",
            "Epoch 86/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5182 - acc: 0.7495\n",
            "Epoch 87/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5181 - acc: 0.7515\n",
            "Epoch 88/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5237 - acc: 0.7456\n",
            "Epoch 89/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5183 - acc: 0.7397\n",
            "Epoch 90/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5209 - acc: 0.7554\n",
            "Epoch 91/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5179 - acc: 0.7515\n",
            "Epoch 92/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5146 - acc: 0.7534\n",
            "Epoch 93/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5229 - acc: 0.7495\n",
            "Epoch 94/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5162 - acc: 0.7476\n",
            "Epoch 95/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5124 - acc: 0.7515\n",
            "Epoch 96/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5136 - acc: 0.7495\n",
            "Epoch 97/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5140 - acc: 0.7417\n",
            "Epoch 98/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5116 - acc: 0.7378\n",
            "Epoch 99/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5120 - acc: 0.7515\n",
            "Epoch 100/100\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5182 - acc: 0.7339\n",
            "257/257 [==============================] - 1s 3ms/step\n",
            "Epoch 1/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5315 - acc: 0.7402\n",
            "Epoch 2/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5281 - acc: 0.7461\n",
            "Epoch 3/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5316 - acc: 0.7402\n",
            "Epoch 4/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5298 - acc: 0.7480\n",
            "Epoch 5/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5288 - acc: 0.7285\n",
            "Epoch 6/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5302 - acc: 0.7402\n",
            "Epoch 7/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5240 - acc: 0.7559\n",
            "Epoch 8/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5207 - acc: 0.7617\n",
            "Epoch 9/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5191 - acc: 0.7363\n",
            "Epoch 10/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5242 - acc: 0.7539\n",
            "Epoch 11/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5264 - acc: 0.7305\n",
            "Epoch 12/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5215 - acc: 0.7461\n",
            "Epoch 13/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5201 - acc: 0.7402\n",
            "Epoch 14/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5156 - acc: 0.7598\n",
            "Epoch 15/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5226 - acc: 0.7305\n",
            "Epoch 16/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5160 - acc: 0.7637\n",
            "Epoch 17/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5153 - acc: 0.7617\n",
            "Epoch 18/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5175 - acc: 0.7480\n",
            "Epoch 19/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5157 - acc: 0.7578\n",
            "Epoch 20/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5058 - acc: 0.7461\n",
            "Epoch 21/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5196 - acc: 0.7480\n",
            "Epoch 22/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5101 - acc: 0.7559\n",
            "Epoch 23/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5128 - acc: 0.7500\n",
            "Epoch 24/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5069 - acc: 0.7617\n",
            "Epoch 25/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5156 - acc: 0.7578\n",
            "Epoch 26/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5163 - acc: 0.7422\n",
            "Epoch 27/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5086 - acc: 0.7422\n",
            "Epoch 28/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5013 - acc: 0.7754\n",
            "Epoch 29/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5074 - acc: 0.7500\n",
            "Epoch 30/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5078 - acc: 0.7539\n",
            "Epoch 31/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5001 - acc: 0.7461\n",
            "Epoch 32/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5064 - acc: 0.7461\n",
            "Epoch 33/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5083 - acc: 0.7383\n",
            "Epoch 34/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5078 - acc: 0.7598\n",
            "Epoch 35/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5129 - acc: 0.7598\n",
            "Epoch 36/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5040 - acc: 0.7578\n",
            "Epoch 37/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5113 - acc: 0.7637\n",
            "Epoch 38/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5006 - acc: 0.7598\n",
            "Epoch 39/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4975 - acc: 0.7559\n",
            "Epoch 40/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5029 - acc: 0.7598\n",
            "Epoch 41/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4964 - acc: 0.7734\n",
            "Epoch 42/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5042 - acc: 0.7480\n",
            "Epoch 43/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5048 - acc: 0.7676\n",
            "Epoch 44/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4992 - acc: 0.7617\n",
            "Epoch 45/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4984 - acc: 0.7598\n",
            "Epoch 46/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5025 - acc: 0.7637\n",
            "Epoch 47/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4936 - acc: 0.7578\n",
            "Epoch 48/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4971 - acc: 0.7480\n",
            "Epoch 49/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5068 - acc: 0.7578\n",
            "Epoch 50/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4942 - acc: 0.7695\n",
            "Epoch 51/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4981 - acc: 0.7695\n",
            "Epoch 52/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4968 - acc: 0.7520\n",
            "Epoch 53/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4976 - acc: 0.7480\n",
            "Epoch 54/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4959 - acc: 0.7559\n",
            "Epoch 55/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4953 - acc: 0.7676\n",
            "Epoch 56/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4913 - acc: 0.7520\n",
            "Epoch 57/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4939 - acc: 0.7559\n",
            "Epoch 58/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4976 - acc: 0.7461\n",
            "Epoch 59/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4950 - acc: 0.7461\n",
            "Epoch 60/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4970 - acc: 0.7539\n",
            "Epoch 61/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4972 - acc: 0.7539\n",
            "Epoch 62/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4911 - acc: 0.7637\n",
            "Epoch 63/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4898 - acc: 0.7676\n",
            "Epoch 64/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4941 - acc: 0.7598\n",
            "Epoch 65/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4926 - acc: 0.7578\n",
            "Epoch 66/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4901 - acc: 0.7539\n",
            "Epoch 67/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4973 - acc: 0.7520\n",
            "Epoch 68/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4840 - acc: 0.7676\n",
            "Epoch 69/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4981 - acc: 0.7598\n",
            "Epoch 70/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4943 - acc: 0.7598\n",
            "Epoch 71/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4869 - acc: 0.7656\n",
            "Epoch 72/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4869 - acc: 0.7656\n",
            "Epoch 73/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5054 - acc: 0.7637\n",
            "Epoch 74/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4846 - acc: 0.7637\n",
            "Epoch 75/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4857 - acc: 0.7637\n",
            "Epoch 76/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4887 - acc: 0.7578\n",
            "Epoch 77/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4844 - acc: 0.7695\n",
            "Epoch 78/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4888 - acc: 0.7656\n",
            "Epoch 79/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4885 - acc: 0.7598\n",
            "Epoch 80/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4881 - acc: 0.7617\n",
            "Epoch 81/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4878 - acc: 0.7520\n",
            "Epoch 82/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4882 - acc: 0.7637\n",
            "Epoch 83/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4928 - acc: 0.7559\n",
            "Epoch 84/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4869 - acc: 0.7598\n",
            "Epoch 85/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4891 - acc: 0.7695\n",
            "Epoch 86/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4908 - acc: 0.7637\n",
            "Epoch 87/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4842 - acc: 0.7637\n",
            "Epoch 88/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4817 - acc: 0.7598\n",
            "Epoch 89/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4828 - acc: 0.7793\n",
            "Epoch 90/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4882 - acc: 0.7559\n",
            "Epoch 91/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4818 - acc: 0.7656\n",
            "Epoch 92/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4857 - acc: 0.7617\n",
            "Epoch 93/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4845 - acc: 0.7656\n",
            "Epoch 94/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4807 - acc: 0.7715\n",
            "Epoch 95/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4883 - acc: 0.7578\n",
            "Epoch 96/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4889 - acc: 0.7676\n",
            "Epoch 97/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4835 - acc: 0.7617\n",
            "Epoch 98/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4827 - acc: 0.7617\n",
            "Epoch 99/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4859 - acc: 0.7637\n",
            "Epoch 100/100\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.4874 - acc: 0.7793\n",
            "256/256 [==============================] - 0s 89us/step\n",
            "Epoch 1/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5164 - acc: 0.7446\n",
            "Epoch 2/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5103 - acc: 0.7485\n",
            "Epoch 3/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5103 - acc: 0.7602\n",
            "Epoch 4/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5031 - acc: 0.7544\n",
            "Epoch 5/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5102 - acc: 0.7719\n",
            "Epoch 6/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5006 - acc: 0.7622\n",
            "Epoch 7/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5072 - acc: 0.7563\n",
            "Epoch 8/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5049 - acc: 0.7466\n",
            "Epoch 9/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5015 - acc: 0.7583\n",
            "Epoch 10/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5026 - acc: 0.7524\n",
            "Epoch 11/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4978 - acc: 0.7583\n",
            "Epoch 12/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4985 - acc: 0.7661\n",
            "Epoch 13/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5003 - acc: 0.7719\n",
            "Epoch 14/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4975 - acc: 0.7680\n",
            "Epoch 15/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5032 - acc: 0.7544\n",
            "Epoch 16/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5016 - acc: 0.7583\n",
            "Epoch 17/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4999 - acc: 0.7524\n",
            "Epoch 18/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4985 - acc: 0.7407\n",
            "Epoch 19/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4967 - acc: 0.7583\n",
            "Epoch 20/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4967 - acc: 0.7758\n",
            "Epoch 21/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4927 - acc: 0.7583\n",
            "Epoch 22/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4878 - acc: 0.7602\n",
            "Epoch 23/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4975 - acc: 0.7680\n",
            "Epoch 24/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4876 - acc: 0.7797\n",
            "Epoch 25/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4933 - acc: 0.7427\n",
            "Epoch 26/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4897 - acc: 0.7641\n",
            "Epoch 27/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4991 - acc: 0.7641\n",
            "Epoch 28/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4892 - acc: 0.7700\n",
            "Epoch 29/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4971 - acc: 0.7700\n",
            "Epoch 30/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4889 - acc: 0.7661\n",
            "Epoch 31/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5033 - acc: 0.7602\n",
            "Epoch 32/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4928 - acc: 0.7661\n",
            "Epoch 33/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4916 - acc: 0.7719\n",
            "Epoch 34/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4936 - acc: 0.7700\n",
            "Epoch 35/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4947 - acc: 0.7719\n",
            "Epoch 36/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4902 - acc: 0.7700\n",
            "Epoch 37/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4912 - acc: 0.7602\n",
            "Epoch 38/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4943 - acc: 0.7661\n",
            "Epoch 39/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4891 - acc: 0.7797\n",
            "Epoch 40/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4831 - acc: 0.7758\n",
            "Epoch 41/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4885 - acc: 0.7739\n",
            "Epoch 42/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4881 - acc: 0.7622\n",
            "Epoch 43/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4867 - acc: 0.7739\n",
            "Epoch 44/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4896 - acc: 0.7700\n",
            "Epoch 45/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4855 - acc: 0.7778\n",
            "Epoch 46/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4763 - acc: 0.7758\n",
            "Epoch 47/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4858 - acc: 0.7680\n",
            "Epoch 48/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4870 - acc: 0.7563\n",
            "Epoch 49/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4898 - acc: 0.7700\n",
            "Epoch 50/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4768 - acc: 0.7797\n",
            "Epoch 51/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4902 - acc: 0.7700\n",
            "Epoch 52/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4895 - acc: 0.7856\n",
            "Epoch 53/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4831 - acc: 0.7505\n",
            "Epoch 54/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4835 - acc: 0.7739\n",
            "Epoch 55/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4879 - acc: 0.7602\n",
            "Epoch 56/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4820 - acc: 0.7758\n",
            "Epoch 57/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4821 - acc: 0.7817\n",
            "Epoch 58/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4845 - acc: 0.7719\n",
            "Epoch 59/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4876 - acc: 0.7524\n",
            "Epoch 60/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4828 - acc: 0.7856\n",
            "Epoch 61/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4789 - acc: 0.7641\n",
            "Epoch 62/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4777 - acc: 0.7797\n",
            "Epoch 63/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4762 - acc: 0.7797\n",
            "Epoch 64/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4791 - acc: 0.7602\n",
            "Epoch 65/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4871 - acc: 0.7758\n",
            "Epoch 66/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4843 - acc: 0.7719\n",
            "Epoch 67/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4780 - acc: 0.7778\n",
            "Epoch 68/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4845 - acc: 0.7739\n",
            "Epoch 69/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4730 - acc: 0.7914\n",
            "Epoch 70/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4839 - acc: 0.7778\n",
            "Epoch 71/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4827 - acc: 0.7680\n",
            "Epoch 72/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4814 - acc: 0.7758\n",
            "Epoch 73/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4810 - acc: 0.7856\n",
            "Epoch 74/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4795 - acc: 0.7856\n",
            "Epoch 75/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4807 - acc: 0.7778\n",
            "Epoch 76/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4810 - acc: 0.7778\n",
            "Epoch 77/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4913 - acc: 0.7622\n",
            "Epoch 78/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4748 - acc: 0.7914\n",
            "Epoch 79/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4840 - acc: 0.7700\n",
            "Epoch 80/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4833 - acc: 0.7758\n",
            "Epoch 81/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4801 - acc: 0.7602\n",
            "Epoch 82/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4813 - acc: 0.7758\n",
            "Epoch 83/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4785 - acc: 0.7856\n",
            "Epoch 84/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4801 - acc: 0.7895\n",
            "Epoch 85/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4744 - acc: 0.7856\n",
            "Epoch 86/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4694 - acc: 0.7680\n",
            "Epoch 87/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4688 - acc: 0.7934\n",
            "Epoch 88/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4715 - acc: 0.7836\n",
            "Epoch 89/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4803 - acc: 0.7778\n",
            "Epoch 90/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4714 - acc: 0.7778\n",
            "Epoch 91/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4779 - acc: 0.7758\n",
            "Epoch 92/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4652 - acc: 0.7797\n",
            "Epoch 93/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4826 - acc: 0.7661\n",
            "Epoch 94/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4722 - acc: 0.7856\n",
            "Epoch 95/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4717 - acc: 0.7700\n",
            "Epoch 96/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4724 - acc: 0.7875\n",
            "Epoch 97/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4766 - acc: 0.7817\n",
            "Epoch 98/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4720 - acc: 0.7914\n",
            "Epoch 99/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4739 - acc: 0.7661\n",
            "Epoch 100/100\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.4722 - acc: 0.7641\n",
            "255/255 [==============================] - 0s 82us/step\n",
            "Finished cross-valiation. Took 2.9 mintues.\n",
            "Mean Accuracy: 75.01%, Standard Deviation: 2.48%\n",
            "\n",
            "Evaluating parameter \"batch_size\" using value \"1\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 4s 9ms/step - loss: 0.6664 - acc: 0.6399\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 3s 6ms/step - loss: 0.6486 - acc: 0.6556\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.6410 - acc: 0.6634\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.6320 - acc: 0.6654\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.6221 - acc: 0.6751\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 3s 6ms/step - loss: 0.6204 - acc: 0.6595\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.6129 - acc: 0.6673\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 3s 6ms/step - loss: 0.6006 - acc: 0.6810\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.6095 - acc: 0.6849\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.5894 - acc: 0.7299\n",
            "257/257 [==============================] - 1s 3ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 3s 5ms/step - loss: 0.5829 - acc: 0.7031\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 3s 6ms/step - loss: 0.5736 - acc: 0.7070\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 3s 5ms/step - loss: 0.5752 - acc: 0.6914\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 3s 5ms/step - loss: 0.5825 - acc: 0.7129\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 3s 5ms/step - loss: 0.5734 - acc: 0.6973\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 3s 6ms/step - loss: 0.5613 - acc: 0.7324\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 3s 5ms/step - loss: 0.5586 - acc: 0.7168\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 3s 5ms/step - loss: 0.5547 - acc: 0.7148\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 3s 5ms/step - loss: 0.5660 - acc: 0.7266\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 3s 6ms/step - loss: 0.5523 - acc: 0.7305\n",
            "256/256 [==============================] - 0s 84us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.6011 - acc: 0.6842\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.5860 - acc: 0.6920\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.5885 - acc: 0.7115\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.5855 - acc: 0.6959\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.5857 - acc: 0.7037\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.5829 - acc: 0.7115\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.5734 - acc: 0.7232\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.5769 - acc: 0.7212\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.5661 - acc: 0.7135\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.5729 - acc: 0.7212\n",
            "255/255 [==============================] - 0s 83us/step\n",
            "Finished cross-valiation. Took 1.4 mintues.\n",
            "Mean Accuracy: 69.01%, Standard Deviation: 1.48%\n",
            "\n",
            "Evaluating parameter \"batch_size\" using value \"5\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.6751 - acc: 0.6301\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6560 - acc: 0.6556\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6473 - acc: 0.6595\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6360 - acc: 0.6654\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6193 - acc: 0.6791\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6129 - acc: 0.6791\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6187 - acc: 0.6791\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.6066 - acc: 0.6967\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5969 - acc: 0.6830\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 1s 1ms/step - loss: 0.5951 - acc: 0.6849\n",
            "257/257 [==============================] - 1s 3ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5962 - acc: 0.6875\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5943 - acc: 0.7012\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5893 - acc: 0.7109\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5747 - acc: 0.7129\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5731 - acc: 0.7207\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5710 - acc: 0.7109\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5791 - acc: 0.6973\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5671 - acc: 0.7109\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5672 - acc: 0.7188\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 1s 1ms/step - loss: 0.5703 - acc: 0.7188\n",
            "256/256 [==============================] - 0s 92us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5773 - acc: 0.7212\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5694 - acc: 0.7251\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5745 - acc: 0.7057\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5758 - acc: 0.7271\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5665 - acc: 0.7446\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5652 - acc: 0.7485\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5660 - acc: 0.7290\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5571 - acc: 0.7407\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5596 - acc: 0.7290\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 0.5658 - acc: 0.7368\n",
            "255/255 [==============================] - 0s 83us/step\n",
            "Finished cross-valiation. Took 0.3 mintues.\n",
            "Mean Accuracy: 70.70%, Standard Deviation: 1.21%\n",
            "\n",
            "Evaluating parameter \"batch_size\" using value \"10\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.6760 - acc: 0.6517\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 0s 582us/step - loss: 0.6625 - acc: 0.6438\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 0s 558us/step - loss: 0.6545 - acc: 0.6556\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 0s 548us/step - loss: 0.6547 - acc: 0.6419\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 0s 604us/step - loss: 0.6491 - acc: 0.6497\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 0s 567us/step - loss: 0.6401 - acc: 0.6614\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 0s 558us/step - loss: 0.6339 - acc: 0.6517\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 0s 558us/step - loss: 0.6229 - acc: 0.6614\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 0s 579us/step - loss: 0.6208 - acc: 0.6634\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 0s 544us/step - loss: 0.6175 - acc: 0.6791\n",
            "257/257 [==============================] - 1s 3ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 0s 548us/step - loss: 0.6067 - acc: 0.6816\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 0s 553us/step - loss: 0.6005 - acc: 0.6992\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 0s 568us/step - loss: 0.6044 - acc: 0.7012\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 0s 568us/step - loss: 0.5902 - acc: 0.7090\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 0s 569us/step - loss: 0.5863 - acc: 0.7012\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 0s 561us/step - loss: 0.5917 - acc: 0.7168\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 0s 582us/step - loss: 0.5810 - acc: 0.7207\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 0s 570us/step - loss: 0.5768 - acc: 0.7148\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 0s 572us/step - loss: 0.5889 - acc: 0.6992\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 0s 590us/step - loss: 0.5745 - acc: 0.7207\n",
            "256/256 [==============================] - 0s 82us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 0s 568us/step - loss: 0.6113 - acc: 0.6881\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 0s 570us/step - loss: 0.5928 - acc: 0.7057\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 0s 593us/step - loss: 0.5952 - acc: 0.7251\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 0s 581us/step - loss: 0.5834 - acc: 0.7154\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 0s 563us/step - loss: 0.5823 - acc: 0.7173\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 0s 577us/step - loss: 0.5812 - acc: 0.7232\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 0s 612us/step - loss: 0.5832 - acc: 0.7193\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 0s 600us/step - loss: 0.5816 - acc: 0.7018\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 0s 603us/step - loss: 0.5790 - acc: 0.7096\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 0s 606us/step - loss: 0.5735 - acc: 0.7232\n",
            "255/255 [==============================] - 0s 85us/step\n",
            "Finished cross-valiation. Took 0.2 mintues.\n",
            "Mean Accuracy: 71.22%, Standard Deviation: 0.21%\n",
            "\n",
            "Evaluating parameter \"batch_size\" using value \"15\"...\n",
            "Starting 3-fold cross-validation...\n",
            "Epoch 1/10\n",
            "511/511 [==============================] - 2s 4ms/step - loss: 0.6667 - acc: 0.6419\n",
            "Epoch 2/10\n",
            "511/511 [==============================] - 0s 380us/step - loss: 0.6561 - acc: 0.6517\n",
            "Epoch 3/10\n",
            "511/511 [==============================] - 0s 431us/step - loss: 0.6508 - acc: 0.6438\n",
            "Epoch 4/10\n",
            "511/511 [==============================] - 0s 388us/step - loss: 0.6407 - acc: 0.6477\n",
            "Epoch 5/10\n",
            "511/511 [==============================] - 0s 399us/step - loss: 0.6404 - acc: 0.6458\n",
            "Epoch 6/10\n",
            "511/511 [==============================] - 0s 402us/step - loss: 0.6319 - acc: 0.6556\n",
            "Epoch 7/10\n",
            "511/511 [==============================] - 0s 400us/step - loss: 0.6292 - acc: 0.6732\n",
            "Epoch 8/10\n",
            "511/511 [==============================] - 0s 415us/step - loss: 0.6271 - acc: 0.6634\n",
            "Epoch 9/10\n",
            "511/511 [==============================] - 0s 377us/step - loss: 0.6183 - acc: 0.6751\n",
            "Epoch 10/10\n",
            "511/511 [==============================] - 0s 386us/step - loss: 0.6306 - acc: 0.6693\n",
            "257/257 [==============================] - 1s 3ms/step\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 0s 380us/step - loss: 0.6078 - acc: 0.6680\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 0s 396us/step - loss: 0.6037 - acc: 0.6738\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 0s 395us/step - loss: 0.6190 - acc: 0.6738\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 0s 386us/step - loss: 0.6089 - acc: 0.6738\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 0s 403us/step - loss: 0.5945 - acc: 0.6836\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 0s 385us/step - loss: 0.5924 - acc: 0.6953\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 0s 386us/step - loss: 0.5869 - acc: 0.6895\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 0s 385us/step - loss: 0.5844 - acc: 0.7070\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 0s 393us/step - loss: 0.5851 - acc: 0.6914\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 0s 404us/step - loss: 0.5795 - acc: 0.7031\n",
            "256/256 [==============================] - 0s 89us/step\n",
            "Epoch 1/10\n",
            "513/513 [==============================] - 0s 379us/step - loss: 0.5849 - acc: 0.7096\n",
            "Epoch 2/10\n",
            "513/513 [==============================] - 0s 393us/step - loss: 0.5776 - acc: 0.7076\n",
            "Epoch 3/10\n",
            "513/513 [==============================] - 0s 391us/step - loss: 0.5779 - acc: 0.7037\n",
            "Epoch 4/10\n",
            "513/513 [==============================] - 0s 392us/step - loss: 0.5808 - acc: 0.7057\n",
            "Epoch 5/10\n",
            "513/513 [==============================] - 0s 416us/step - loss: 0.5812 - acc: 0.7173\n",
            "Epoch 6/10\n",
            "513/513 [==============================] - 0s 386us/step - loss: 0.5654 - acc: 0.7037\n",
            "Epoch 7/10\n",
            "513/513 [==============================] - 0s 378us/step - loss: 0.5625 - acc: 0.7193\n",
            "Epoch 8/10\n",
            "513/513 [==============================] - 0s 378us/step - loss: 0.5655 - acc: 0.7096\n",
            "Epoch 9/10\n",
            "513/513 [==============================] - 0s 397us/step - loss: 0.5665 - acc: 0.7135\n",
            "Epoch 10/10\n",
            "513/513 [==============================] - 0s 415us/step - loss: 0.5561 - acc: 0.7271\n",
            "255/255 [==============================] - 0s 101us/step\n",
            "Finished cross-valiation. Took 0.2 mintues.\n",
            "Mean Accuracy: 69.93%, Standard Deviation: 1.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kozw8MO7Iu3I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('cross_validation_results.pkl', 'rb') as f:\n",
        "    tuning_results = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTns86tjLRDq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def wrangle(tuning_results):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "        tuning_results: dict, the dict loaded from pickled hyperparameter tuning results\n",
        "    \n",
        "    Returns:\n",
        "        df_long: pandas df, the wrangled long format dataframe\n",
        "    \"\"\"\n",
        "    # Save as df\n",
        "    df = pd.DataFrame(tuning_results)\n",
        "    # Get the col names as value vars for melt func\n",
        "    value_vars = df.columns.tolist()\n",
        "    # Reset index and rename the index col \n",
        "    df = df.reset_index().rename(columns={'index': 'option'})\n",
        "    # Transform from wide to long format for easy plotting\n",
        "    df_long = pd.melt(df, id_vars='option', value_vars=value_vars)\n",
        "    df_long = df_long.rename(columns={'variable': 'parameter'})\n",
        "    # Exclude the zero and null values\n",
        "    df_long = df_long[~df_long['value'].isnull()]\n",
        "    df_long = df_long.query(\"value!=0 & value!='NaN'\")\n",
        "    \n",
        "    return df_long"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r5d4uGxUa73N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "c8b27493-419c-4c35-9406-286da59379b7"
      },
      "cell_type": "code",
      "source": [
        "df_long = wrangle(tuning_results)\n",
        "fig, ax = plt.subplots(figsize=(16, 10))\n",
        "df_long.boxplot(column='value', by='parameter', ax=ax)\n",
        "plt.ylim(0.5, 0.8)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8IAAAKCCAYAAAAaxGB1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1dfce37b70>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "b9eHEi1jrARQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}